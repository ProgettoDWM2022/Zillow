{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELPU3bTvsRXC"
   },
   "source": [
    "# Predictions \n",
    "## Niccolò Simonato \n",
    "## Data & Web Mining, Academic Year 2021-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dependencies and the cleaned dataset\n",
    "\n",
    "The cleaned dataset is now imported.\n",
    "\n",
    "The first snipped is intended to be used in the Google Drive environment, just set the path variable as needed.\n",
    "\n",
    "The second one is intended to be used in the Jupyter Notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "_x2HBMo0iWLY"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# path = '/gdrive/MyDrive/Progetto DWM/Data/*.csv'\n",
    "# %cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "OlRC0QJQiT25"
   },
   "outputs": [],
   "source": [
    "path = 'Data/'\n",
    "\n",
    "# cleaned_df = pd.read_csv(path, low_memory = False)\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_datasets.append(pd.read_csv(f\"{path}train_dataset_2016_{i + 1}.csv\", low_memory = True))\n",
    "    test_datasets.append(pd.read_csv(f\"{path}test_dataset_2016_{i + 1}.csv\", low_memory = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation\n",
    "In order to prevent any exception to be raised, we will check the state of each dataset and will ensure that the data can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>parcelid</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>calculatedbathnbr</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>finishedsquarefeet12</th>\n",
       "      <th>fips</th>\n",
       "      <th>...</th>\n",
       "      <th>N-LogTaxScore</th>\n",
       "      <th>N-zip_count</th>\n",
       "      <th>N-city_count</th>\n",
       "      <th>N-ACInd</th>\n",
       "      <th>N-HeatInd</th>\n",
       "      <th>N-PropType</th>\n",
       "      <th>N-Dev-structuretaxvaluedollarcnt</th>\n",
       "      <th>DD</th>\n",
       "      <th>MM</th>\n",
       "      <th>N-DaysInCurrentYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>68208.000000</td>\n",
       "      <td>6.820800e+04</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.00000</td>\n",
       "      <td>68208.000000</td>\n",
       "      <td>68208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49638.060931</td>\n",
       "      <td>1.300474e+07</td>\n",
       "      <td>3.945578</td>\n",
       "      <td>2.270320</td>\n",
       "      <td>3.003636</td>\n",
       "      <td>5.521900</td>\n",
       "      <td>2.288236</td>\n",
       "      <td>1743.108272</td>\n",
       "      <td>1743.108272</td>\n",
       "      <td>6049.177223</td>\n",
       "      <td>...</td>\n",
       "      <td>9.147980</td>\n",
       "      <td>324.725560</td>\n",
       "      <td>4834.738476</td>\n",
       "      <td>0.329390</td>\n",
       "      <td>0.654718</td>\n",
       "      <td>0.051050</td>\n",
       "      <td>0.530811</td>\n",
       "      <td>16.36267</td>\n",
       "      <td>5.867875</td>\n",
       "      <td>164.342922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27218.525092</td>\n",
       "      <td>2.371372e+06</td>\n",
       "      <td>2.279430</td>\n",
       "      <td>0.940313</td>\n",
       "      <td>1.009035</td>\n",
       "      <td>1.529856</td>\n",
       "      <td>1.017559</td>\n",
       "      <td>905.997275</td>\n",
       "      <td>905.997275</td>\n",
       "      <td>20.860330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681050</td>\n",
       "      <td>177.343462</td>\n",
       "      <td>7380.803303</td>\n",
       "      <td>0.469995</td>\n",
       "      <td>0.475464</td>\n",
       "      <td>0.314264</td>\n",
       "      <td>0.757977</td>\n",
       "      <td>9.00774</td>\n",
       "      <td>2.803042</td>\n",
       "      <td>85.483391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.071174e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6037.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.824880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31590.000000</td>\n",
       "      <td>1.154383e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1171.000000</td>\n",
       "      <td>1171.000000</td>\n",
       "      <td>6037.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.754919</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198509</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54141.500000</td>\n",
       "      <td>1.258943e+07</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.565407</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>6037.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.181586</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405284</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>167.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72214.250000</td>\n",
       "      <td>1.425394e+07</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2055.000000</td>\n",
       "      <td>2055.000000</td>\n",
       "      <td>6059.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.559402</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>2703.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648437</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90272.000000</td>\n",
       "      <td>1.629608e+08</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20013.000000</td>\n",
       "      <td>20013.000000</td>\n",
       "      <td>6111.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.951033</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>18697.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.442360</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>365.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      parcelid  airconditioningtypeid   bathroomcnt  \\\n",
       "count  68208.000000  6.820800e+04           68208.000000  68208.000000   \n",
       "mean   49638.060931  1.300474e+07               3.945578      2.270320   \n",
       "std    27218.525092  2.371372e+06               2.279430      0.940313   \n",
       "min        0.000000  1.071174e+07               1.000000      0.000000   \n",
       "25%    31590.000000  1.154383e+07               1.000000      2.000000   \n",
       "50%    54141.500000  1.258943e+07               5.000000      2.000000   \n",
       "75%    72214.250000  1.425394e+07               5.000000      3.000000   \n",
       "max    90272.000000  1.629608e+08              13.000000     20.000000   \n",
       "\n",
       "         bedroomcnt  buildingqualitytypeid  calculatedbathnbr  \\\n",
       "count  68208.000000           68208.000000       68208.000000   \n",
       "mean       3.003636               5.521900           2.288236   \n",
       "std        1.009035               1.529856           1.017559   \n",
       "min        0.000000               1.000000           1.000000   \n",
       "25%        2.000000               4.000000           2.000000   \n",
       "50%        3.000000               5.565407           2.000000   \n",
       "75%        4.000000               7.000000           3.000000   \n",
       "max       10.000000              12.000000          20.000000   \n",
       "\n",
       "       calculatedfinishedsquarefeet  finishedsquarefeet12          fips  ...  \\\n",
       "count                  68208.000000          68208.000000  68208.000000  ...   \n",
       "mean                    1743.108272           1743.108272   6049.177223  ...   \n",
       "std                      905.997275            905.997275     20.860330  ...   \n",
       "min                        2.000000              2.000000   6037.000000  ...   \n",
       "25%                     1171.000000           1171.000000   6037.000000  ...   \n",
       "50%                     1515.000000           1515.000000   6037.000000  ...   \n",
       "75%                     2055.000000           2055.000000   6059.000000  ...   \n",
       "max                    20013.000000          20013.000000   6111.000000  ...   \n",
       "\n",
       "       N-LogTaxScore   N-zip_count  N-city_count       N-ACInd     N-HeatInd  \\\n",
       "count   68208.000000  68208.000000  68208.000000  68208.000000  68208.000000   \n",
       "mean        9.147980    324.725560   4834.738476      0.329390      0.654718   \n",
       "std         0.681050    177.343462   7380.803303      0.469995      0.475464   \n",
       "min         4.824880      1.000000      1.000000      0.000000      0.000000   \n",
       "25%         8.754919    198.000000    432.000000      0.000000      0.000000   \n",
       "50%         9.181586    296.000000    992.000000      0.000000      1.000000   \n",
       "75%         9.559402    399.000000   2703.000000      1.000000      1.000000   \n",
       "max        12.951033    902.000000  18697.000000      1.000000      1.000000   \n",
       "\n",
       "         N-PropType  N-Dev-structuretaxvaluedollarcnt           DD  \\\n",
       "count  68208.000000                      68208.000000  68208.00000   \n",
       "mean       0.051050                          0.530811     16.36267   \n",
       "std        0.314264                          0.757977      9.00774   \n",
       "min        0.000000                          0.000000      1.00000   \n",
       "25%        0.000000                          0.198509      8.00000   \n",
       "50%        0.000000                          0.405284     16.00000   \n",
       "75%        0.000000                          0.648437     24.00000   \n",
       "max        2.000000                         39.442360     31.00000   \n",
       "\n",
       "                 MM  N-DaysInCurrentYear  \n",
       "count  68208.000000         68208.000000  \n",
       "mean       5.867875           164.342922  \n",
       "std        2.803042            85.483391  \n",
       "min        1.000000             1.000000  \n",
       "25%        4.000000            97.000000  \n",
       "50%        6.000000           167.000000  \n",
       "75%        8.000000           232.000000  \n",
       "max       12.000000           365.000000  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[1].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have any real use for it, we can drop the parcelid feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_datasets:\n",
    "    i.drop(['parcelid'], axis=1, inplace=True)\n",
    "\n",
    "for i in test_datasets:\n",
    "    i.drop(['parcelid'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar8xvJ5kbrgl"
   },
   "source": [
    "## Predictions - Attempt 1 - k-NN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TdV2Wm4b8jx"
   },
   "source": [
    "### Why k-NN? - Introduction \n",
    "I chose the k-NN algorithm because, usually, the house construction doesn't happen randomly. It's really unusual that a private party builds his own house, with his own money, and wherever he likes: it's more likely that the municipality's dedicated office decides where and how the houses of a given zone are buildt. \n",
    "\n",
    "Therefore, i think is safe to assume that houses of a given zone will have similar prices. The k-NN hopefully will help achiving this target, especially if we tune the geolocalization features with a greater weight over the other ones. \n",
    "\n",
    "This attempt will use the [ScikitLearn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) of the k-NN algorithm for prediction.\n",
    "\n",
    "The first attempt will be conducted with the parameter \"weights\" set as \"uniform\", the second one will use the value \"distance\".\n",
    "\n",
    "The model will be tested with a number of neighbors beetween 4 and 8, because usually these are the value that yield the best results.\n",
    "\n",
    "The following snippet contains the functions that wraps the described procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "7FkaJft9tOR2"
   },
   "outputs": [],
   "source": [
    "n_neighbors = [4,5,6,7,8]\n",
    "    \n",
    "def train_test_kNN(x_train, y_train, x_test, y_test, n_neighbors, w='uniform'):\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors, weights=w)\n",
    "    model = knn.fit(x_train, y_train)\n",
    "    prediction = model.predict(x_test)\n",
    "    scores = model.score(x_test, y_test)\n",
    "    data = {'x_train': x_train,\n",
    "            'y_train': y_train,\n",
    "            'x_test': x_test,\n",
    "            'y_test': y_test,\n",
    "            'n_neighbors': n_neighbors, \n",
    "            'weights': w,\n",
    "            'prediction': prediction,\n",
    "            'score' : scores,\n",
    "           }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_datasets[1]\n",
    "test = test_datasets[1]\n",
    "to_Y = ['logerror']\n",
    "to_X = list(set(train.columns) - set('logerror'))\n",
    "result = train_test_kNN(train[to_X], train[to_Y], test[to_X], test[to_Y], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "types = ['distance', 'uniform']\n",
    "to_Y = ['logerror']\n",
    "to_X = list(set(train.columns) - set('logerror'))\n",
    "for train in train_datasets:\n",
    "    for test in test_datasets:\n",
    "        for n in n_neighbors:\n",
    "            for w in types:\n",
    "                results.append(train_test_kNN(train[to_X], train[to_Y], test[to_X], test[to_Y], n, w))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPlmoW8Bd0UP"
   },
   "source": [
    "### How did it go? - Evaluation\n",
    "After obtaining the results, we can proceed with the evaluation of the results.\n",
    "\n",
    "In order to keep this notebook as clean as possible, the evaluation will be done with the built-in evaluator of the KNeighborsRegressor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "dkMbdppjvYVu"
   },
   "outputs": [],
   "source": [
    "def show_results_kNN(data):\n",
    "    for i in data:\n",
    "        parameters = i\n",
    "        if parameters['weights'] == 'uniform':\n",
    "            col = 'darkorange'\n",
    "        else:\n",
    "            col = 'blue'\n",
    "        plt.scatter(parameters['n_neighbors'], parameters['score'], color=col, label='data')\n",
    "    plt.title(f\"KNeighborsRegressor\")\n",
    "    plt.show()\n",
    "\n",
    "# plt.subplot(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results_kNN(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVUf7WUQcI33"
   },
   "source": [
    "## Predictions - Attempt 2 - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jkCHkx0Hdsj"
   },
   "source": [
    "### Why Linear Regression? - Introduction\n",
    "The idea behind the adoption of the LinReg model is correlated to the low integrity of the inititial dataset. \n",
    "\n",
    "In contrast with the previously analyzed model, this is an attempt to see what would happen with an \"assumption-free\" model. It is expected that this type of analysis will underline some unseen correlations, and also will produce some interesting predictions.\n",
    "\n",
    "This test will be conducted with the [ScikitLearn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) of the LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3N2szLiTv7Oi"
   },
   "outputs": [],
   "source": [
    "def train_test_LinReg(x_train, y_train, x_test, y_test):\n",
    "    model = LinearRegression().fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    data = {\n",
    "        'x_train': x_train,\n",
    "        'y_train': y_train,\n",
    "        'x_test': x_test,\n",
    "        'y_test': y_test,\n",
    "        'predictions': predictions,\n",
    "        'R_sq': model.score(y_test, predictions)\n",
    "        'MSE': mean_squared_error(y_test, predictions)\n",
    "    }\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for train in train_datasets:\n",
    "    for test in test_datasets:\n",
    "        res.append(train_test_LinReg(train.loc[:, train.columns!='logerror'], train['logerror'], test.loc[:, test.columns!='logerror'], test['logerror']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHbgkxaTJqKL"
   },
   "source": [
    "### How did it go? - Evaluation\n",
    "We can now proceed with the evaluation of the results.\n",
    "\n",
    "The following tests will be used:\n",
    "\n",
    "\n",
    "*  Mean Squared Error\n",
    "*  R-squared index\n",
    "\n",
    "\n",
    "The evaluations will be done by using the [ScikitLearn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results_LinReg(parameters):\n",
    "    R_sq = model.score(parameters['x_test'],parameters['y_test']) #R-squared index\n",
    "    MSE = mean_squared_error(parameters['y_test'], parameters['predictions']) #Mean Squared Error\n",
    "\n",
    "    plt.scatter(parameters['x_train'], parameters['y_train'], color=\"darkorange\", label=\"data\")\n",
    "    plt.plot(parameters['x_test'], parameters['predictions'], color=\"navy\", label=\"prediction\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"LinearRegressor\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plt.subplot(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in res:\n",
    "    show_results_LinReg(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Prediction - Simonato.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
