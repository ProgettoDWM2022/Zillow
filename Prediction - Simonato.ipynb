{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELPU3bTvsRXC"
   },
   "source": [
    "# Predictions \n",
    "## Niccol√≤ Simonato \n",
    "## Data & Web Mining, Academic Year 2021-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dependencies and the cleaned dataset\n",
    "\n",
    "The cleaned dataset is now imported.\n",
    "\n",
    "The first snipped is intended to be used in the Google Drive environment, just set the path variable as needed.\n",
    "\n",
    "The second one is intended to be used in the Jupyter Notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from math import floor, log10\n",
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_x2HBMo0iWLY"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# path = '/gdrive/MyDrive/Progetto DWM/Data/*.csv'\n",
    "# %cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OlRC0QJQiT25"
   },
   "outputs": [],
   "source": [
    "path = 'Data/'\n",
    "\n",
    "# cleaned_df = pd.read_csv(path, low_memory = False)\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for i in range(4):\n",
    "    train_datasets.append(pd.read_csv(f\"{path}train_dataset_2016_{i + 1}.csv\", low_memory = True))\n",
    "    test_datasets.append(pd.read_csv(f\"{path}test_dataset_2016_{i + 1}.csv\", low_memory = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation\n",
    "In order to prevent any exception to be raised, we will check the state of each dataset and will ensure that the data can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>parcelid</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>propertycountylandusecode</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>logerror</th>\n",
       "      <th>N-LivingAreaError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63945.000000</td>\n",
       "      <td>6.394500e+04</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.0</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48882.100227</td>\n",
       "      <td>1.300342e+07</td>\n",
       "      <td>1744.500774</td>\n",
       "      <td>0.451234</td>\n",
       "      <td>0.661069</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>16.667683</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28905.336939</td>\n",
       "      <td>2.423721e+06</td>\n",
       "      <td>904.481611</td>\n",
       "      <td>0.181467</td>\n",
       "      <td>0.192405</td>\n",
       "      <td>0.016580</td>\n",
       "      <td>18.109890</td>\n",
       "      <td>0.020831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.071174e+07</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>-3.194000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16874.000000</td>\n",
       "      <td>1.154290e+07</td>\n",
       "      <td>1172.000000</td>\n",
       "      <td>0.317044</td>\n",
       "      <td>0.544646</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>-0.024300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56386.000000</td>\n",
       "      <td>1.258800e+07</td>\n",
       "      <td>1516.000000</td>\n",
       "      <td>0.462381</td>\n",
       "      <td>0.678780</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73348.000000</td>\n",
       "      <td>1.425320e+07</td>\n",
       "      <td>2059.000000</td>\n",
       "      <td>0.566001</td>\n",
       "      <td>0.809982</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90272.000000</td>\n",
       "      <td>1.629608e+08</td>\n",
       "      <td>20013.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.737000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      parcelid  calculatedfinishedsquarefeet      latitude  \\\n",
       "count  63945.000000  6.394500e+04                  63945.000000  63945.000000   \n",
       "mean   48882.100227  1.300342e+07                   1744.500774      0.451234   \n",
       "std    28905.336939  2.423721e+06                    904.481611      0.181467   \n",
       "min        0.000000  1.071174e+07                      2.000000      0.000000   \n",
       "25%    16874.000000  1.154290e+07                   1172.000000      0.317044   \n",
       "50%    56386.000000  1.258800e+07                   1516.000000      0.462381   \n",
       "75%    73348.000000  1.425320e+07                   2059.000000      0.566001   \n",
       "max    90272.000000  1.629608e+08                  20013.000000      1.000000   \n",
       "\n",
       "          longitude  lotsizesquarefeet  propertycountylandusecode  \\\n",
       "count  63945.000000       63945.000000               63945.000000   \n",
       "mean       0.661069           0.003954                  16.667683   \n",
       "std        0.192405           0.016580                  18.109890   \n",
       "min        0.000000           0.000000                   0.000000   \n",
       "25%        0.544646           0.000765                   1.000000   \n",
       "50%        0.678780           0.000992                   8.000000   \n",
       "75%        0.809982           0.001610                  38.000000   \n",
       "max        1.000000           1.000000                  51.000000   \n",
       "\n",
       "       structuretaxvaluedollarcnt  assessmentyear      logerror  \\\n",
       "count                63945.000000         63945.0  63945.000000   \n",
       "mean                     0.018100          2015.0      0.012324   \n",
       "std                      0.020831             0.0      0.155913   \n",
       "min                      0.000000          2015.0     -3.194000   \n",
       "25%                      0.008191          2015.0     -0.024300   \n",
       "50%                      0.013270          2015.0      0.006000   \n",
       "75%                      0.021189          2015.0      0.038300   \n",
       "max                      1.000000          2015.0      4.737000   \n",
       "\n",
       "       N-LivingAreaError  \n",
       "count            63945.0  \n",
       "mean                 1.0  \n",
       "std                  0.0  \n",
       "min                  1.0  \n",
       "25%                  1.0  \n",
       "50%                  1.0  \n",
       "75%                  1.0  \n",
       "max                  1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[1].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have any real use for it, we can drop the `parcelid` feature. We will also drop , `Unnamed: 0` because it's a duplicate of `parcelid`.\n",
    "\n",
    "`assessmentyear` and `N-LivingAreaError` can be also dropped since the remaining values are for the most part the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_datasets:\n",
    "    i.drop(['parcelid','Unnamed: 0','assessmentyear', 'N-LivingAreaError'], axis=1, inplace=True)\n",
    "\n",
    "for i in test_datasets:\n",
    "    i.drop(['parcelid','Unnamed: 0','assessmentyear', 'N-LivingAreaError'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the scales of the values we have left. It looks like some features such as `calculatedfinishedsquarefeet` and `propertycountylandusecode` have much larger scales than the others. We will rescale all the features to the interval $[0,1]$, in order to have standardized values. We will use the same function that we used in the EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxRescaling(features, min_v=0, max_v=1):\n",
    "    scaler = MinMaxScaler(feature_range=(min_v, max_v), copy=False) #in place\n",
    "    scaler.fit(features)\n",
    "    return scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_datasets:\n",
    "    i[['calculatedfinishedsquarefeet','propertycountylandusecode']] = MinMaxRescaling(i[['calculatedfinishedsquarefeet','propertycountylandusecode']])\n",
    "\n",
    "for i in test_datasets:\n",
    "    i[['calculatedfinishedsquarefeet','propertycountylandusecode']] = MinMaxRescaling(i[['calculatedfinishedsquarefeet','propertycountylandusecode']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar8xvJ5kbrgl"
   },
   "source": [
    "## Predictions - Attempt 1 - k-NN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TdV2Wm4b8jx"
   },
   "source": [
    "### Why k-NN? - Introduction \n",
    "I chose the k-NN algorithm because, usually, the house construction doesn't happen randomly. It's really unusual that a private party builds his own house, with his own money, and wherever he likes: it's more likely that the municipality's dedicated office decides where and how the houses of a given zone are going to be buildt. \n",
    "\n",
    "Therefore, i think is safe to assume that houses of a given zone will have similar prices. The k-NN hopefully will help achiving this target. \n",
    "\n",
    "This attempt will use the [ScikitLearn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) of the k-NN algorithm for prediction.\n",
    "\n",
    "The first attempt will be conducted with the parameter `weights` set as \"uniform\", the second one will use the value \"distance\".\n",
    "\n",
    "The model will be tested with a number of neighbors beetween 2 and 20, because usually these are the value that yield the best results.\n",
    "\n",
    "The following snippet contains the functions that wrap the described procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7FkaJft9tOR2"
   },
   "outputs": [],
   "source": [
    "train, test = None, None\n",
    "n_neighbors = list(range(2,21))\n",
    "results = []\n",
    "types = ['distance', 'uniform']\n",
    "to_Y = ['logerror']\n",
    "to_X = list(set(train_datasets[1].columns) - set('logerror'))\n",
    "def train_test_kNN(x_train, y_train, x_test, y_test, n_neighbors, w='distance'):\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors, weights=w)\n",
    "    model = knn.fit(x_train, y_train)\n",
    "    prediction = model.predict(x_test)\n",
    "    scores = model.score(x_test, y_test)\n",
    "    diff = x_test.copy()\n",
    "    diff['diff'] = y_test - prediction\n",
    "    diff['diff'] = diff['diff'].abs()\n",
    "    data = {'n_neighbors': n_neighbors, \n",
    "            'weights': w,\n",
    "            'prediction': prediction,\n",
    "            'score' : scores,\n",
    "            'MSE': mean_squared_error(y_test,prediction),\n",
    "            'diff': diff\n",
    "           }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START - Dataset 1] at 2022-06-14 13:43:53.527486: n_neighbor = 2, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:43:54.661744 after 1.134258 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:43:54.662835: n_neighbor = 2, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:43:55.785128 after 1.122293 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:43:55.785128: n_neighbor = 3, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:43:57.026520 after 1.241392 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:43:57.026520: n_neighbor = 3, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:43:58.361202 after 1.334682 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:43:58.361202: n_neighbor = 4, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:43:59.659443 after 1.298241 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:43:59.659644: n_neighbor = 4, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:00.970355 after 1.310711 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:00.970355: n_neighbor = 5, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:02.341061 after 1.370706 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:02.341061: n_neighbor = 5, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:03.719010 after 1.377949 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:03.719010: n_neighbor = 6, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:05.161493 after 1.442483 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:05.161493: n_neighbor = 6, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:06.611755 after 1.450262 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:06.611755: n_neighbor = 7, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:08.106629 after 1.494874 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:08.106629: n_neighbor = 7, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:09.580905 after 1.474276 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:09.580905: n_neighbor = 8, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:11.139890 after 1.558985 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:11.139890: n_neighbor = 8, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:12.693436 after 1.553546 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:12.693436: n_neighbor = 9, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:14.464525 after 1.771089 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:14.464910: n_neighbor = 9, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:16.081855 after 1.616945 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:16.081855: n_neighbor = 10, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:17.743136 after 1.661281 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:17.743136: n_neighbor = 10, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:19.386386 after 1.64325 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:19.386386: n_neighbor = 11, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:21.092013 after 1.705627 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:21.092013: n_neighbor = 11, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:22.814512 after 1.722499 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:22.814512: n_neighbor = 12, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:24.570203 after 1.755691 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:24.570203: n_neighbor = 12, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:26.318098 after 1.747895 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:26.318098: n_neighbor = 13, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:28.133672 after 1.815574 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:28.133672: n_neighbor = 13, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:30.039693 after 1.906021 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:30.039693: n_neighbor = 14, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:31.916933 after 1.87724 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:31.916933: n_neighbor = 14, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:33.749777 after 1.832844 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:33.749777: n_neighbor = 15, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:35.626602 after 1.876825 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:35.626602: n_neighbor = 15, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:37.492214 after 1.865612 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:37.492214: n_neighbor = 16, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:39.392356 after 1.900142 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:39.392356: n_neighbor = 16, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:41.318855 after 1.926499 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:41.318855: n_neighbor = 17, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:43.271819 after 1.952964 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:43.271819: n_neighbor = 17, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:45.229538 after 1.957719 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:45.229538: n_neighbor = 18, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:47.298654 after 2.069116 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:47.298654: n_neighbor = 18, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:49.310205 after 2.011551 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:49.310205: n_neighbor = 19, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:51.329552 after 2.019347 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:51.329552: n_neighbor = 19, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:53.364282 after 2.03473 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:53.364282: n_neighbor = 20, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:55.419181 after 2.054899 seconds. \n",
      "[START - Dataset 1] at 2022-06-14 13:44:55.419181: n_neighbor = 20, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-14 13:44:57.481951 after 2.06277 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:44:57.481951: n_neighbor = 2, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:44:58.334192 after 0.852241 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:44:58.334192: n_neighbor = 2, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:44:59.196173 after 0.861981 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:44:59.196173: n_neighbor = 3, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:00.147946 after 0.951773 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:00.147946: n_neighbor = 3, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:01.111390 after 0.963444 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:01.111390: n_neighbor = 4, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:02.238137 after 1.126747 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:02.238137: n_neighbor = 4, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:03.241802 after 1.003665 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:03.247500: n_neighbor = 5, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:04.300711 after 1.053211 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:04.300711: n_neighbor = 5, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:05.359824 after 1.059113 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:05.359824: n_neighbor = 6, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:06.481703 after 1.121879 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:06.481703: n_neighbor = 6, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:07.594983 after 1.11328 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:07.594983: n_neighbor = 7, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:08.753184 after 1.158201 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:08.753184: n_neighbor = 7, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:09.960014 after 1.20683 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:09.960014: n_neighbor = 8, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:11.172291 after 1.212277 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:11.172291: n_neighbor = 8, weight = uniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[END   - Dataset 2] at 2022-06-14 13:45:12.373742 after 1.201451 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:12.373742: n_neighbor = 9, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:13.618650 after 1.244908 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:13.618650: n_neighbor = 9, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:14.869739 after 1.251089 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:14.869739: n_neighbor = 10, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:16.155318 after 1.285579 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:16.155318: n_neighbor = 10, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:17.522540 after 1.367222 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:17.523175: n_neighbor = 11, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:18.935701 after 1.412526 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:18.935701: n_neighbor = 11, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:20.271094 after 1.335393 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:20.271094: n_neighbor = 12, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:21.682539 after 1.411445 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:21.682539: n_neighbor = 12, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:23.055806 after 1.373267 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:23.055806: n_neighbor = 13, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:24.478892 after 1.423086 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:24.478892: n_neighbor = 13, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:25.886194 after 1.407302 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:25.886194: n_neighbor = 14, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:27.324122 after 1.437928 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:27.324122: n_neighbor = 14, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:28.773032 after 1.44891 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:28.773032: n_neighbor = 15, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:30.284109 after 1.511077 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:30.284109: n_neighbor = 15, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:31.776496 after 1.492387 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:31.776496: n_neighbor = 16, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:33.338502 after 1.562006 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:33.339625: n_neighbor = 16, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:34.959265 after 1.61964 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:34.959265: n_neighbor = 17, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:36.510564 after 1.551299 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:36.510564: n_neighbor = 17, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:38.073925 after 1.563361 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:38.073925: n_neighbor = 18, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:39.647906 after 1.573981 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:39.647906: n_neighbor = 18, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:41.235662 after 1.587756 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:41.235662: n_neighbor = 19, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:42.850637 after 1.614975 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:42.851260: n_neighbor = 19, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:44.849489 after 1.998229 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:44.849489: n_neighbor = 20, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:46.716815 after 1.867326 seconds. \n",
      "[START - Dataset 2] at 2022-06-14 13:45:46.716815: n_neighbor = 20, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-14 13:45:50.779610 after 4.062795 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:45:50.779610: n_neighbor = 2, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:45:53.234952 after 2.455342 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:45:53.236055: n_neighbor = 2, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:45:54.269148 after 1.033093 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:45:54.269148: n_neighbor = 3, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:45:55.120671 after 0.851523 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:45:55.120671: n_neighbor = 3, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:45:55.982576 after 0.861905 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:45:55.982576: n_neighbor = 4, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:45:56.914288 after 0.931712 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:45:56.914288: n_neighbor = 4, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:45:57.860779 after 0.946491 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:45:57.860779: n_neighbor = 5, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:45:58.839808 after 0.979029 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:45:58.839808: n_neighbor = 5, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:45:59.848112 after 1.008304 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:45:59.848112: n_neighbor = 6, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:01.789360 after 1.941248 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:01.789360: n_neighbor = 6, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:04.497715 after 2.708355 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:04.504866: n_neighbor = 7, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:08.250745 after 3.745879 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:08.250745: n_neighbor = 7, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:09.440652 after 1.189907 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:09.441277: n_neighbor = 8, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:10.569249 after 1.127972 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:10.569249: n_neighbor = 8, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:11.675606 after 1.106357 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:11.675606: n_neighbor = 9, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:12.840280 after 1.164674 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:12.840280: n_neighbor = 9, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:13.989950 after 1.14967 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:13.989950: n_neighbor = 10, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:15.220992 after 1.231042 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:15.220992: n_neighbor = 10, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:16.458182 after 1.23719 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:16.458233: n_neighbor = 11, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:19.728322 after 3.270089 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:19.728322: n_neighbor = 11, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:23.174573 after 3.446251 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:23.174573: n_neighbor = 12, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:25.256018 after 2.081445 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:25.256018: n_neighbor = 12, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:26.526241 after 1.270223 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:26.526241: n_neighbor = 13, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:27.835005 after 1.308764 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:27.835005: n_neighbor = 13, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:29.125117 after 1.290112 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:29.125117: n_neighbor = 14, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:30.674411 after 1.549294 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:30.674411: n_neighbor = 14, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:32.056884 after 1.382473 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:32.056884: n_neighbor = 15, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:33.455877 after 1.398993 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:33.455877: n_neighbor = 15, weight = uniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[END   - Dataset 3] at 2022-06-14 13:46:34.875890 after 1.420013 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:34.876895: n_neighbor = 16, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:36.332283 after 1.455388 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:36.332283: n_neighbor = 16, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:37.871926 after 1.539643 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:37.871926: n_neighbor = 17, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:39.429891 after 1.557965 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:39.429891: n_neighbor = 17, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:40.937899 after 1.508008 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:40.938905: n_neighbor = 18, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:42.511695 after 1.57279 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:42.511695: n_neighbor = 18, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:44.004807 after 1.493112 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:44.004807: n_neighbor = 19, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:45.532259 after 1.527452 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:45.532259: n_neighbor = 19, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:47.056771 after 1.524512 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:47.056771: n_neighbor = 20, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:48.592525 after 1.535754 seconds. \n",
      "[START - Dataset 3] at 2022-06-14 13:46:48.592525: n_neighbor = 20, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-14 13:46:50.148426 after 1.555901 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:46:50.148426: n_neighbor = 2, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:46:51.036039 after 0.887613 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:46:51.036039: n_neighbor = 2, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:46:51.942230 after 0.906191 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:46:51.942230: n_neighbor = 3, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:46:52.907959 after 0.965729 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:46:52.907959: n_neighbor = 3, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:46:53.978581 after 1.070622 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:46:53.979001: n_neighbor = 4, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:46:55.085522 after 1.106521 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:46:55.085522: n_neighbor = 4, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:46:56.143816 after 1.058294 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:46:56.143816: n_neighbor = 5, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:46:57.959874 after 1.816058 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:46:57.959874: n_neighbor = 5, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:00.687230 after 2.727356 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:00.687230: n_neighbor = 6, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:03.721301 after 3.034071 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:03.721301: n_neighbor = 6, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:05.377191 after 1.65589 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:05.377191: n_neighbor = 7, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:06.572851 after 1.19566 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:06.572851: n_neighbor = 7, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:07.879694 after 1.306843 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:07.880310: n_neighbor = 8, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:09.172204 after 1.291894 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:09.172204: n_neighbor = 8, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:10.535499 after 1.363295 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:10.535499: n_neighbor = 9, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:11.852159 after 1.31666 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:11.852159: n_neighbor = 9, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:13.720097 after 1.867938 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:13.720097: n_neighbor = 10, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:16.956115 after 3.236018 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:16.956115: n_neighbor = 10, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:20.492118 after 3.536003 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:20.492118: n_neighbor = 11, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:21.916628 after 1.42451 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:21.916628: n_neighbor = 11, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:23.285662 after 1.369034 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:23.285662: n_neighbor = 12, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:24.711656 after 1.425994 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:24.711656: n_neighbor = 12, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:26.257777 after 1.546121 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:26.258777: n_neighbor = 13, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:27.725370 after 1.466593 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:27.725370: n_neighbor = 13, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:29.176259 after 1.450889 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:29.176259: n_neighbor = 14, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:30.690107 after 1.513848 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:30.690107: n_neighbor = 14, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:32.193240 after 1.503133 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:32.193240: n_neighbor = 15, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:33.740874 after 1.547634 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:33.741506: n_neighbor = 15, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:35.277023 after 1.535517 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:35.277023: n_neighbor = 16, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:36.859478 after 1.582455 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:36.859478: n_neighbor = 16, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:38.454204 after 1.594726 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:38.454821: n_neighbor = 17, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:40.107457 after 1.652636 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:40.107457: n_neighbor = 17, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:41.817848 after 1.710391 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:41.817848: n_neighbor = 18, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:43.547946 after 1.730098 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:43.547946: n_neighbor = 18, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:45.227665 after 1.679719 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:45.227665: n_neighbor = 19, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:46.948110 after 1.720445 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:46.948110: n_neighbor = 19, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:48.642015 after 1.693905 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:48.642015: n_neighbor = 20, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:50.387321 after 1.745306 seconds. \n",
      "[START - Dataset 4] at 2022-06-14 13:47:50.387321: n_neighbor = 20, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-14 13:47:52.121031 after 1.73371 seconds. \n",
      "CPU times: total: 3min 55s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(train_datasets)):\n",
    "    train = train_datasets[i]\n",
    "    test  = test_datasets[i]\n",
    "    for n in n_neighbors:\n",
    "        for w in types:\n",
    "            timestamp1 = datetime.now()\n",
    "            print(f\"[START - Dataset {i + 1}] at {timestamp1}: n_neighbor = {n}, weight = {w}\")\n",
    "            results.append(train_test_kNN(train[to_X], train[to_Y], test[to_X], test[to_Y], n, w))\n",
    "            timestamp2 = datetime.now()\n",
    "            difference = timestamp2 - timestamp1\n",
    "            print(f\"[END   - Dataset {i + 1}] at {timestamp2} after {difference.total_seconds()} seconds. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPlmoW8Bd0UP"
   },
   "source": [
    "### How did it go? - Evaluation\n",
    "After obtaining the results, we can proceed with the evaluation of the results.\n",
    "\n",
    "In order to keep this notebook as clean as possible, the evaluation will be done with the built-in evaluator of the KNeighborsRegressor object. The evaluation uses the $R^2$ index, the coefficient of determination that is $1 - \\frac{u}{v}$, where $u$ is the residual sum of squares and $v$ is the total sum of squares.\n",
    "\n",
    "We will also use the function \"mean_squared_error\" from Sklearn's module \"metrics\", to calculate the $MSE$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dkMbdppjvYVu"
   },
   "outputs": [],
   "source": [
    "def set_subplot(ax, title, x_label, y_label, color, par):\n",
    "    ax.scatter(par['n_neighbors'], par['score'], color=color, label='data')\n",
    "    ax.get_yaxis().get_major_formatter().set_useOffset(False)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "\n",
    "def show_results_kNN(data):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "    for parameters in data:\n",
    "        if parameters['weights'] == \"uniform\":\n",
    "            set_subplot(ax1, 'Uniform', 'Number of neighbors', 'R^2 index', 'darkorange', parameters)\n",
    "            set_subplot(ax3, '', 'Number of neighbors', 'Mean Squared Error', 'darkorange', parameters)\n",
    "        else:\n",
    "            set_subplot(ax2, 'Distance', 'Number of neighbors', '', 'blue', parameters)\n",
    "            set_subplot(ax4, '', 'Number of neighbors', '', 'blue', parameters)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results_kNN(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to remind that by default the \"distance\" used in those cases is the Minkowski distance. With other parameters, it may have yielded other results, but for the purpose of this project it is a reasonable choice.\n",
    "\n",
    "These results show that the parameter \"weights\" yields comparable scores for the two tested values. It looks like the $R^2 index$ gets better as the number of neighbors approaches 5, then it slowly decreases. It happens more or less the same for the $MSE$, but this metric decreases after the aforementioned value.\n",
    "\n",
    "The results are acceptable for the means of this project, and show that the algorithm probably did not overfit. It is advisable though that more tests are conducted with the 2017 dataset. The value of the $MSE$ metric suggests that the model's precision can be improved. It looks like increasing the value of $k$ may lower the $MSE$, but an high value of $k$ would lead to biased results.\n",
    "\n",
    "We will now try to find some pattern from the instances that yielded the best results and the ones that yielded the worst ones. This comparison will be repeated for the two models with the best and the worst scores.\n",
    "\n",
    "In order to obtain the best and the worst models, they will be sorted in descending order by the $R^2$ index value and then in ascending order by the $MSE$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = results\n",
    "best.sort(key=lambda p: p['score'], reverse=True)\n",
    "best.sort(key=lambda p: p['MSE'])\n",
    "worst = best[len(best) - 1]\n",
    "best = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>logerror</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>propertycountylandusecode</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>longitude</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.440396</td>\n",
       "      <td>-0.110762</td>\n",
       "      <td>0.053052</td>\n",
       "      <td>0.227041</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.464772</td>\n",
       "      <td>1.663783e-02</td>\n",
       "      <td>0.102431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.213676</td>\n",
       "      <td>1.540660</td>\n",
       "      <td>0.035170</td>\n",
       "      <td>0.302395</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.268347</td>\n",
       "      <td>1.084010e-02</td>\n",
       "      <td>0.218259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000508</td>\n",
       "      <td>-3.194000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>4.020909e-07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.387312</td>\n",
       "      <td>-0.108950</td>\n",
       "      <td>0.032819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.424665</td>\n",
       "      <td>1.034721e-02</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.449701</td>\n",
       "      <td>-0.024900</td>\n",
       "      <td>0.065164</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.566136</td>\n",
       "      <td>1.556770e-02</td>\n",
       "      <td>0.008030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.569596</td>\n",
       "      <td>0.030275</td>\n",
       "      <td>0.077320</td>\n",
       "      <td>0.270408</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>2.229144e-02</td>\n",
       "      <td>0.055793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.695250</td>\n",
       "      <td>2.544000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>0.687121</td>\n",
       "      <td>3.230448e-02</td>\n",
       "      <td>0.627611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  logerror  calculatedfinishedsquarefeet  \\\n",
       "count  8.000000  8.000000                      8.000000   \n",
       "mean   0.440396 -0.110762                      0.053052   \n",
       "std    0.213676  1.540660                      0.035170   \n",
       "min    0.000508 -3.194000                      0.000000   \n",
       "25%    0.387312 -0.108950                      0.032819   \n",
       "50%    0.449701 -0.024900                      0.065164   \n",
       "75%    0.569596  0.030275                      0.077320   \n",
       "max    0.695250  2.544000                      0.090000   \n",
       "\n",
       "       propertycountylandusecode  lotsizesquarefeet  longitude  \\\n",
       "count                   8.000000           8.000000   8.000000   \n",
       "mean                    0.227041           0.001473   0.464772   \n",
       "std                     0.302395           0.001621   0.268347   \n",
       "min                     0.000000           0.000038   0.000270   \n",
       "25%                     0.000000           0.000392   0.424665   \n",
       "50%                     0.132653           0.001072   0.566136   \n",
       "75%                     0.270408           0.001915   0.615957   \n",
       "max                     0.755102           0.005007   0.687121   \n",
       "\n",
       "       structuretaxvaluedollarcnt      diff  \n",
       "count                8.000000e+00  8.000000  \n",
       "mean                 1.663783e-02  0.102431  \n",
       "std                  1.084010e-02  0.218259  \n",
       "min                  4.020909e-07  0.000000  \n",
       "25%                  1.034721e-02  0.000525  \n",
       "50%                  1.556770e-02  0.008030  \n",
       "75%                  2.229144e-02  0.055793  \n",
       "max                  3.230448e-02  0.627611  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best['diff'].iloc[best['diff'].idxmin(), :].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>logerror</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>propertycountylandusecode</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>longitude</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.440396</td>\n",
       "      <td>-0.110762</td>\n",
       "      <td>0.053052</td>\n",
       "      <td>0.227041</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.464772</td>\n",
       "      <td>1.663783e-02</td>\n",
       "      <td>0.102431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.213676</td>\n",
       "      <td>1.540660</td>\n",
       "      <td>0.035170</td>\n",
       "      <td>0.302395</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.268347</td>\n",
       "      <td>1.084010e-02</td>\n",
       "      <td>0.218259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000508</td>\n",
       "      <td>-3.194000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>4.020909e-07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.387312</td>\n",
       "      <td>-0.108950</td>\n",
       "      <td>0.032819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.424665</td>\n",
       "      <td>1.034721e-02</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.449701</td>\n",
       "      <td>-0.024900</td>\n",
       "      <td>0.065164</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.566136</td>\n",
       "      <td>1.556770e-02</td>\n",
       "      <td>0.008030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.569596</td>\n",
       "      <td>0.030275</td>\n",
       "      <td>0.077320</td>\n",
       "      <td>0.270408</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.615957</td>\n",
       "      <td>2.229144e-02</td>\n",
       "      <td>0.055793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.695250</td>\n",
       "      <td>2.544000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>0.687121</td>\n",
       "      <td>3.230448e-02</td>\n",
       "      <td>0.627611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  logerror  calculatedfinishedsquarefeet  \\\n",
       "count  8.000000  8.000000                      8.000000   \n",
       "mean   0.440396 -0.110762                      0.053052   \n",
       "std    0.213676  1.540660                      0.035170   \n",
       "min    0.000508 -3.194000                      0.000000   \n",
       "25%    0.387312 -0.108950                      0.032819   \n",
       "50%    0.449701 -0.024900                      0.065164   \n",
       "75%    0.569596  0.030275                      0.077320   \n",
       "max    0.695250  2.544000                      0.090000   \n",
       "\n",
       "       propertycountylandusecode  lotsizesquarefeet  longitude  \\\n",
       "count                   8.000000           8.000000   8.000000   \n",
       "mean                    0.227041           0.001473   0.464772   \n",
       "std                     0.302395           0.001621   0.268347   \n",
       "min                     0.000000           0.000038   0.000270   \n",
       "25%                     0.000000           0.000392   0.424665   \n",
       "50%                     0.132653           0.001072   0.566136   \n",
       "75%                     0.270408           0.001915   0.615957   \n",
       "max                     0.755102           0.005007   0.687121   \n",
       "\n",
       "       structuretaxvaluedollarcnt      diff  \n",
       "count                8.000000e+00  8.000000  \n",
       "mean                 1.663783e-02  0.102431  \n",
       "std                  1.084010e-02  0.218259  \n",
       "min                  4.020909e-07  0.000000  \n",
       "25%                  1.034721e-02  0.000525  \n",
       "50%                  1.556770e-02  0.008030  \n",
       "75%                  2.229144e-02  0.055793  \n",
       "max                  3.230448e-02  0.627611  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best['diff'].iloc[best['diff'].idxmin(), :].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>logerror</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>propertycountylandusecode</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>longitude</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.532889</td>\n",
       "      <td>-0.010650</td>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.549781</td>\n",
       "      <td>0.013023</td>\n",
       "      <td>0.006504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.125792</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.048920</td>\n",
       "      <td>0.365520</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.223157</td>\n",
       "      <td>0.008153</td>\n",
       "      <td>0.009554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.370947</td>\n",
       "      <td>-0.086600</td>\n",
       "      <td>0.023406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.086196</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.460788</td>\n",
       "      <td>-0.030475</td>\n",
       "      <td>0.061210</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.514919</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.528398</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>0.075310</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.541001</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>0.002623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.616546</td>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.102305</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.656849</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>0.005289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.733355</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.173376</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.812639</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>0.029010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  logerror  calculatedfinishedsquarefeet  \\\n",
       "count  8.000000  8.000000                      8.000000   \n",
       "mean   0.532889 -0.010650                      0.083004   \n",
       "std    0.125792  0.041200                      0.048920   \n",
       "min    0.370947 -0.086600                      0.023406   \n",
       "25%    0.460788 -0.030475                      0.061210   \n",
       "50%    0.528398 -0.002500                      0.075310   \n",
       "75%    0.616546  0.014150                      0.102305   \n",
       "max    0.733355  0.041100                      0.173376   \n",
       "\n",
       "       propertycountylandusecode  lotsizesquarefeet  longitude  \\\n",
       "count                   8.000000           8.000000   8.000000   \n",
       "mean                    0.321429           0.002065   0.549781   \n",
       "std                     0.365520           0.001794   0.223157   \n",
       "min                     0.000000           0.000691   0.086196   \n",
       "25%                     0.015306           0.001186   0.514919   \n",
       "50%                     0.142857           0.001498   0.541001   \n",
       "75%                     0.704082           0.002030   0.656849   \n",
       "max                     0.795918           0.006303   0.812639   \n",
       "\n",
       "       structuretaxvaluedollarcnt      diff  \n",
       "count                    8.000000  8.000000  \n",
       "mean                     0.013023  0.006504  \n",
       "std                      0.008153  0.009554  \n",
       "min                      0.003308  0.001300  \n",
       "25%                      0.008570  0.001346  \n",
       "50%                      0.012126  0.002623  \n",
       "75%                      0.016457  0.005289  \n",
       "max                      0.028841  0.029010  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst['diff'].iloc[best['diff'].idxmin(), :].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>logerror</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>propertycountylandusecode</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>longitude</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.532889</td>\n",
       "      <td>-0.010650</td>\n",
       "      <td>0.083004</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.549781</td>\n",
       "      <td>0.013023</td>\n",
       "      <td>0.006504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.125792</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.048920</td>\n",
       "      <td>0.365520</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.223157</td>\n",
       "      <td>0.008153</td>\n",
       "      <td>0.009554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.370947</td>\n",
       "      <td>-0.086600</td>\n",
       "      <td>0.023406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.086196</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.460788</td>\n",
       "      <td>-0.030475</td>\n",
       "      <td>0.061210</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.514919</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.528398</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>0.075310</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.541001</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>0.002623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.616546</td>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.102305</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.656849</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>0.005289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.733355</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.173376</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.812639</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>0.029010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  logerror  calculatedfinishedsquarefeet  \\\n",
       "count  8.000000  8.000000                      8.000000   \n",
       "mean   0.532889 -0.010650                      0.083004   \n",
       "std    0.125792  0.041200                      0.048920   \n",
       "min    0.370947 -0.086600                      0.023406   \n",
       "25%    0.460788 -0.030475                      0.061210   \n",
       "50%    0.528398 -0.002500                      0.075310   \n",
       "75%    0.616546  0.014150                      0.102305   \n",
       "max    0.733355  0.041100                      0.173376   \n",
       "\n",
       "       propertycountylandusecode  lotsizesquarefeet  longitude  \\\n",
       "count                   8.000000           8.000000   8.000000   \n",
       "mean                    0.321429           0.002065   0.549781   \n",
       "std                     0.365520           0.001794   0.223157   \n",
       "min                     0.000000           0.000691   0.086196   \n",
       "25%                     0.015306           0.001186   0.514919   \n",
       "50%                     0.142857           0.001498   0.541001   \n",
       "75%                     0.704082           0.002030   0.656849   \n",
       "max                     0.795918           0.006303   0.812639   \n",
       "\n",
       "       structuretaxvaluedollarcnt      diff  \n",
       "count                    8.000000  8.000000  \n",
       "mean                     0.013023  0.006504  \n",
       "std                      0.008153  0.009554  \n",
       "min                      0.003308  0.001300  \n",
       "25%                      0.008570  0.001346  \n",
       "50%                      0.012126  0.002623  \n",
       "75%                      0.016457  0.005289  \n",
       "max                      0.028841  0.029010  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst['diff'].iloc[best['diff'].idxmin(), :].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major differences that emerges are the following:\n",
    "\n",
    "* The best predicted and the worst predicted instances for both the best model are very similar.\n",
    "* The same thing happens with the worst model.\n",
    "* The best predicted instances are located in different places than the worst ones.\n",
    "* The scale for the logerror is wider in the best predicted instances.\n",
    "* The `structuretaxvaluedollarcnt` feature has a much lower scale in the best prediction instances.\n",
    "* The best predicted instances have a larger scale even for the `diff` values.\n",
    "* The worst predicted instances have a larger scale for the `calculatedfinishedsquarefeet` feature values.\n",
    "\n",
    "The other differences that may emerge do not seem to be relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVUf7WUQcI33"
   },
   "source": [
    "## Predictions - Attempt 2 - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jkCHkx0Hdsj"
   },
   "source": [
    "### Why Linear Regression? - Introduction\n",
    "The idea behind the adoption of the LinReg model is correlated to the low integrity of the inititial dataset. \n",
    "\n",
    "In contrast with the previously analyzed model, this is an attempt to see what would happen with an \"assumption-free\" model. It is expected that this type of analysis will underline some unseen correlations, and also will produce some interesting predictions.\n",
    "\n",
    "This test will be conducted with the [ScikitLearn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) of the LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3N2szLiTv7Oi"
   },
   "outputs": [],
   "source": [
    "def train_test_LinReg(x_train, y_train, x_test, y_test):\n",
    "    model = LinearRegression().fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    diff = x_test.copy()\n",
    "    diff['diff'] = y_test - predictions\n",
    "    diff['diff'] = diff['diff'].abs()\n",
    "    data = {\n",
    "        'predictions': predictions,\n",
    "        'R_sq': model.score(x_test, predictions),\n",
    "        'MSE': mean_squared_error(y_test, predictions),\n",
    "        'Adj_R_sq': 1 - (1-model.score(x_test, predictions))*(len(predictions)-1)/(len(predictions)-x_test.shape[1]-1),\n",
    "        'diff': diff\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 250 ms\n",
      "Wall time: 91.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = []\n",
    "to_Y = ['logerror']\n",
    "to_X = list(set(train.columns) - set('logerror'))\n",
    "for i in range(len(train_datasets)):\n",
    "    train = train_datasets[i]\n",
    "    test = test_datasets[i]\n",
    "    res.append(train_test_LinReg(train[to_X], train[to_Y], test[to_X], test[to_Y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHbgkxaTJqKL"
   },
   "source": [
    "### How did it go? - Evaluation\n",
    "We can now proceed with the evaluation of the results.\n",
    "\n",
    "The following tests will be used:\n",
    "\n",
    "*  Mean Squared Error\n",
    "*  R-squared index\n",
    "*  Adjusted R-squared index\n",
    "\n",
    "The evaluations will be done by using the [ScikitLearn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results_LinReg(results):\n",
    "    for i in range(len(results)):\n",
    "        parameters = results[i]\n",
    "        print(f\"[Experiment number {i  + 1}]\\n[Scores] R_sq index = {parameters['R_sq']}, \" + \n",
    "              f\"MSE = {parameters['MSE']}, Adj_R_sq index = {parameters['Adj_R_sq']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Experiment number 1]\n",
      "[Scores] R_sq index = 1.0, MSE = 5.967436434310222e-33, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 2]\n",
      "[Scores] R_sq index = 1.0, MSE = 2.494852540839675e-33, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 3]\n",
      "[Scores] R_sq index = 1.0, MSE = 2.5353992495151337e-32, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 4]\n",
      "[Scores] R_sq index = 1.0, MSE = 4.713595874672913e-32, Adj_R_sq index = 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_results_LinReg(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the results it is clear that the results are too good to be true. It is clear that this is a case of overfitting. [This article](https://statisticsbyjim.com/regression/r-squared-too-high/) explains the other possible reasons of these results. The final section of the document investigates the causes of this failure.\n",
    "\n",
    "It may have been interesting analysing the best and the worst prediction instances for the test conducted in this section, but it's clear that that would be pointless, due to the overall failure of the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVUf7WUQcI33"
   },
   "source": [
    "## Predictions - Attempt 3 - Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jkCHkx0Hdsj"
   },
   "source": [
    "### Why Support Vector Regression? - Introduction\n",
    "\n",
    "After the failure of the Linear Regression Model, this one should yield better results.\n",
    "\n",
    "This test will be conducted with the [ScikitLearn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) of the Support Vector Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3N2szLiTv7Oi"
   },
   "outputs": [],
   "source": [
    "def train_test_SVR(x_train, y_train, x_test, y_test, C_val, Ep_val):\n",
    "    model = SVR(C=C_val, epsilon=Ep_val).fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    data = {\n",
    "        'C': C_val,\n",
    "        'epsilon': Ep_val,\n",
    "        'predictions': predictions,\n",
    "        'R_sq': model.score(x_test, predictions),\n",
    "        'MSE': mean_squared_error(y_test, predictions),\n",
    "        'Adj_R_sq': 1 - (1-model.score(x_test, predictions))*(len(predictions)-1)/(len(predictions)-x_test.shape[1]-1),\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be tested with the `C` parameter values ranging in $[0.8,1.2]$, and the values of the `epsilon` parameter ranging in $[0.1,0.3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 57 s\n",
      "Wall time: 56.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_svr = []\n",
    "to_Y = ['logerror']\n",
    "to_X = list(set(train.columns) - set('logerror'))\n",
    "C_values = [0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3]\n",
    "Ep_values = [0.1,0.2,0.3]\n",
    "for i in range(len(train_datasets)):\n",
    "    train = train_datasets[i]\n",
    "    test = test_datasets[i]\n",
    "    for c in C_values:\n",
    "        for ep in Ep_values:\n",
    "            res_svr.append(train_test_SVR(train[to_X], train[to_Y], test[to_X], test[to_Y], c, ep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHbgkxaTJqKL"
   },
   "source": [
    "### How did it go? - Evaluation\n",
    "We can now proceed with the evaluation of the results.\n",
    "\n",
    "The following tests will be used:\n",
    "\n",
    "*  Mean Squared Error\n",
    "*  R-squared index\n",
    "*  Adjusted R-squared index\n",
    "\n",
    "The evaluations will be done by using the [ScikitLearn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results_SVR(results):\n",
    "    for i in range(len(results)):\n",
    "        parameters = results[i]\n",
    "        print(f\"[Experiment number {i  + 1}] \\n\" +\n",
    "              f\"[Parameters] C: {parameters['C']}, epsilon: {parameters['epsilon']}\"\n",
    "              f\"\\n[Scores] R_sq index = {parameters['R_sq']}, \" + \n",
    "              f\"MSE = {parameters['MSE']}, Adj_R_sq index = {parameters['Adj_R_sq']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Experiment number 1] \n",
      "[Parameters] C: 0.6, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002424487554749362, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 2] \n",
      "[Parameters] C: 0.6, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002694874463456799, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 3] \n",
      "[Parameters] C: 0.6, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0060151919766776646, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 4] \n",
      "[Parameters] C: 0.7, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021951545067371756, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 5] \n",
      "[Parameters] C: 0.7, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0030302801623625754, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 6] \n",
      "[Parameters] C: 0.7, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005280923123244967, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 7] \n",
      "[Parameters] C: 0.8, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021892767249635987, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 8] \n",
      "[Parameters] C: 0.8, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.003086891142018873, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 9] \n",
      "[Parameters] C: 0.8, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0052433544639923935, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 10] \n",
      "[Parameters] C: 0.9, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002177320741707772, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 11] \n",
      "[Parameters] C: 0.9, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0031225000916725227, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 12] \n",
      "[Parameters] C: 0.9, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005062354017790992, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 13] \n",
      "[Parameters] C: 1.0, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021357055925233493, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 14] \n",
      "[Parameters] C: 1.0, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0030986724274021183, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 15] \n",
      "[Parameters] C: 1.0, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.004904240120367091, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 16] \n",
      "[Parameters] C: 1.1, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0020797319031677034, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 17] \n",
      "[Parameters] C: 1.1, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0030885216941622727, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 18] \n",
      "[Parameters] C: 1.1, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.004791597574693047, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 19] \n",
      "[Parameters] C: 1.2, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021201046714906684, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 20] \n",
      "[Parameters] C: 1.2, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0029596566453689273, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 21] \n",
      "[Parameters] C: 1.2, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.004018013332161865, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 22] \n",
      "[Parameters] C: 1.3, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0020922441936872442, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 23] \n",
      "[Parameters] C: 1.3, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002687085689636241, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 24] \n",
      "[Parameters] C: 1.3, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0031311773168437185, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 25] \n",
      "[Parameters] C: 0.6, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006466319249013688, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 26] \n",
      "[Parameters] C: 0.6, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007262030142715328, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 27] \n",
      "[Parameters] C: 0.6, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0122966983025437, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 28] \n",
      "[Parameters] C: 0.7, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006581180923061194, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 29] \n",
      "[Parameters] C: 0.7, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.00734183345860103, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 30] \n",
      "[Parameters] C: 0.7, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.013934649369517377, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 31] \n",
      "[Parameters] C: 0.8, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0062163476647920145, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 32] \n",
      "[Parameters] C: 0.8, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007423121010810404, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 33] \n",
      "[Parameters] C: 0.8, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.016241649939286153, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 34] \n",
      "[Parameters] C: 0.9, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006000486306746537, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 35] \n",
      "[Parameters] C: 0.9, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007415172257029835, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 36] \n",
      "[Parameters] C: 0.9, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.017991426676703563, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 37] \n",
      "[Parameters] C: 1.0, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005793786220610276, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 38] \n",
      "[Parameters] C: 1.0, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007371740724894941, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 39] \n",
      "[Parameters] C: 1.0, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.018275513746518535, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 40] \n",
      "[Parameters] C: 1.1, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005702891322064945, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 41] \n",
      "[Parameters] C: 1.1, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007293108398685417, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 42] \n",
      "[Parameters] C: 1.1, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0184262235741515, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 43] \n",
      "[Parameters] C: 1.2, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005583902717160468, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 44] \n",
      "[Parameters] C: 1.2, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007161914628782112, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 45] \n",
      "[Parameters] C: 1.2, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.01858633833718243, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 46] \n",
      "[Parameters] C: 1.3, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.00553941558509197, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 47] \n",
      "[Parameters] C: 1.3, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007106174364234151, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 48] \n",
      "[Parameters] C: 1.3, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.018724344114688683, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 49] \n",
      "[Parameters] C: 0.6, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021960273237753257, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 50] \n",
      "[Parameters] C: 0.6, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021953592362557927, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 51] \n",
      "[Parameters] C: 0.6, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0035910476161968093, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 52] \n",
      "[Parameters] C: 0.7, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0022627035058707876, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 53] \n",
      "[Parameters] C: 0.7, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002185163836304772, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 54] \n",
      "[Parameters] C: 0.7, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0037218090364184195, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 55] \n",
      "[Parameters] C: 0.8, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0022169944790057295, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 56] \n",
      "[Parameters] C: 0.8, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021775749516119458, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 57] \n",
      "[Parameters] C: 0.8, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0037102476172599617, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 58] \n",
      "[Parameters] C: 0.9, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0022271924163899787, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 59] \n",
      "[Parameters] C: 0.9, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0020971473621103124, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 60] \n",
      "[Parameters] C: 0.9, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.003463823301677706, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 61] \n",
      "[Parameters] C: 1.0, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002272983996687674, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 62] \n",
      "[Parameters] C: 1.0, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0019585480889859775, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 63] \n",
      "[Parameters] C: 1.0, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.003114952770073622, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 64] \n",
      "[Parameters] C: 1.1, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0022939275504217627, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 65] \n",
      "[Parameters] C: 1.1, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0017957371239509404, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 66] \n",
      "[Parameters] C: 1.1, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0028164928816861133, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 67] \n",
      "[Parameters] C: 1.2, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021599247395853735, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 68] \n",
      "[Parameters] C: 1.2, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0016222776562294183, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 69] \n",
      "[Parameters] C: 1.2, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0026302909053977004, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 70] \n",
      "[Parameters] C: 1.3, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002110023930868907, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 71] \n",
      "[Parameters] C: 1.3, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.001496761735542678, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 72] \n",
      "[Parameters] C: 1.3, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002543873080063591, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 73] \n",
      "[Parameters] C: 0.6, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.001100287370597048, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 74] \n",
      "[Parameters] C: 0.6, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005312480378074025, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 75] \n",
      "[Parameters] C: 0.6, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.011194671151141639, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 76] \n",
      "[Parameters] C: 0.7, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0010774782656346909, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 77] \n",
      "[Parameters] C: 0.7, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0066404340530026185, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 78] \n",
      "[Parameters] C: 0.7, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.01226049883104311, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 79] \n",
      "[Parameters] C: 0.8, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0010247669046061147, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 80] \n",
      "[Parameters] C: 0.8, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006860322174502615, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 81] \n",
      "[Parameters] C: 0.8, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.012557427784073009, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 82] \n",
      "[Parameters] C: 0.9, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0010292433205024466, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 83] \n",
      "[Parameters] C: 0.9, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006920362014964069, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 84] \n",
      "[Parameters] C: 0.9, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.013805552420664608, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 85] \n",
      "[Parameters] C: 1.0, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.001028882317501239, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 86] \n",
      "[Parameters] C: 1.0, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007189304007506831, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 87] \n",
      "[Parameters] C: 1.0, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.014749520799148347, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 88] \n",
      "[Parameters] C: 1.1, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.001019392927290443, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 89] \n",
      "[Parameters] C: 1.1, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0072282647643823455, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 90] \n",
      "[Parameters] C: 1.1, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.014883621652723635, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 91] \n",
      "[Parameters] C: 1.2, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0010228869023331264, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 92] \n",
      "[Parameters] C: 1.2, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006945545018154402, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 93] \n",
      "[Parameters] C: 1.2, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.012502280268190854, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 94] \n",
      "[Parameters] C: 1.3, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0009757394833515839, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 95] \n",
      "[Parameters] C: 1.3, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006086818111351059, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 96] \n",
      "[Parameters] C: 1.3, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.010006032199306854, Adj_R_sq index = 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_results_SVR(res_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not as good as expected. The $R^2$ index is still very high, but this time the $MSE$ is reasonably low.\n",
    "\n",
    "This might be another case of overfitting. The causes of this may be the same as the ones found for the Linear Regression.\n",
    "\n",
    "Analysing the best and the worst prediction instances for the test conducted in this section would be pointless, for the same reasons as the previous algorithm tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN\n",
    "It is clear that the first regression algorithm is a more reasonable choice then the second one. \n",
    "\n",
    "The k-NN algorithm did get the expected results. All the evaluation measures turned out to be very high. This is usually a good thing, but not necessarly in this case. The $R^2$ index near to 99% is good, but the $MSE$ at similar values indicates that the model's precision can be improved.\n",
    "\n",
    "### LinReg & SVR\n",
    "The LinReg and the SVR models suffer from a suspect case of over-fitting, so the results are probably biased.\n",
    "\n",
    "The causes of these algorithms' failures may be found among the following:\n",
    "\n",
    "- `Data-related issues`: it is possible that, in the Explorative Data Analysis, the filling of the missing data may have lead to some kind of poisoning. The low number of training instances may be another possible cause.\n",
    "- `Wrong algorithm/approach`: the first and most probable cause, is the inner workings of the Linear Regression: it may just be the wrong model to obtain any useful information from.\n",
    "- `Biased evaluation indexes`: the second possibile cause is a bias contained in the testing measures. The analysis of other indexes may yield some more interesting results, but for now is impossible to declare the precise reason for the over-fitting to happen.\n",
    "\n",
    "It is advisable to use a different algorithm and a more complete dataset to retrieve better results.\n",
    "\n",
    "In order to confirm the overfitting, a test should be conducted with the data from the 2017 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Prediction - Simonato.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
