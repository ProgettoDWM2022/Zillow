{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELPU3bTvsRXC"
   },
   "source": [
    "# Predictions \n",
    "## Niccol√≤ Simonato \n",
    "## Data & Web Mining, Academic Year 2021-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dependencies and the cleaned dataset\n",
    "\n",
    "The cleaned dataset is now imported.\n",
    "\n",
    "The first snipped is intended to be used in the Google Drive environment, just set the path variable as needed.\n",
    "\n",
    "The second one is intended to be used in the Jupyter Notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from math import floor, log10\n",
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_x2HBMo0iWLY"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# path = '/gdrive/MyDrive/Progetto DWM/Data/*.csv'\n",
    "# %cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OlRC0QJQiT25"
   },
   "outputs": [],
   "source": [
    "path = 'Data/'\n",
    "\n",
    "# cleaned_df = pd.read_csv(path, low_memory = False)\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for i in range(4):\n",
    "    train_datasets.append(pd.read_csv(f\"{path}train_dataset_2016_{i + 1}.csv\", low_memory = True))\n",
    "    test_datasets.append(pd.read_csv(f\"{path}test_dataset_2016_{i + 1}.csv\", low_memory = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation\n",
    "In order to prevent any exception to be raised, we will check the state of each dataset and will ensure that the data can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>parcelid</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>propertycountylandusecode</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>logerror</th>\n",
       "      <th>N-LivingAreaError</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63945.000000</td>\n",
       "      <td>6.394500e+04</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.0</td>\n",
       "      <td>63945.000000</td>\n",
       "      <td>63945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48882.100227</td>\n",
       "      <td>1.300342e+07</td>\n",
       "      <td>1744.500774</td>\n",
       "      <td>0.451234</td>\n",
       "      <td>0.661069</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>16.667683</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28905.336939</td>\n",
       "      <td>2.423721e+06</td>\n",
       "      <td>904.481611</td>\n",
       "      <td>0.181467</td>\n",
       "      <td>0.192405</td>\n",
       "      <td>0.016580</td>\n",
       "      <td>18.109890</td>\n",
       "      <td>0.020831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.071174e+07</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>-3.194000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16874.000000</td>\n",
       "      <td>1.154290e+07</td>\n",
       "      <td>1172.000000</td>\n",
       "      <td>0.317044</td>\n",
       "      <td>0.544646</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>-0.024300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56386.000000</td>\n",
       "      <td>1.258800e+07</td>\n",
       "      <td>1516.000000</td>\n",
       "      <td>0.462381</td>\n",
       "      <td>0.678780</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73348.000000</td>\n",
       "      <td>1.425320e+07</td>\n",
       "      <td>2059.000000</td>\n",
       "      <td>0.566001</td>\n",
       "      <td>0.809982</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90272.000000</td>\n",
       "      <td>1.629608e+08</td>\n",
       "      <td>20013.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>4.737000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      parcelid  calculatedfinishedsquarefeet      latitude  \\\n",
       "count  63945.000000  6.394500e+04                  63945.000000  63945.000000   \n",
       "mean   48882.100227  1.300342e+07                   1744.500774      0.451234   \n",
       "std    28905.336939  2.423721e+06                    904.481611      0.181467   \n",
       "min        0.000000  1.071174e+07                      2.000000      0.000000   \n",
       "25%    16874.000000  1.154290e+07                   1172.000000      0.317044   \n",
       "50%    56386.000000  1.258800e+07                   1516.000000      0.462381   \n",
       "75%    73348.000000  1.425320e+07                   2059.000000      0.566001   \n",
       "max    90272.000000  1.629608e+08                  20013.000000      1.000000   \n",
       "\n",
       "          longitude  lotsizesquarefeet  propertycountylandusecode  \\\n",
       "count  63945.000000       63945.000000               63945.000000   \n",
       "mean       0.661069           0.003954                  16.667683   \n",
       "std        0.192405           0.016580                  18.109890   \n",
       "min        0.000000           0.000000                   0.000000   \n",
       "25%        0.544646           0.000765                   1.000000   \n",
       "50%        0.678780           0.000992                   8.000000   \n",
       "75%        0.809982           0.001610                  38.000000   \n",
       "max        1.000000           1.000000                  51.000000   \n",
       "\n",
       "       structuretaxvaluedollarcnt  assessmentyear      logerror  \\\n",
       "count                63945.000000         63945.0  63945.000000   \n",
       "mean                     0.018100          2015.0      0.012324   \n",
       "std                      0.020831             0.0      0.155913   \n",
       "min                      0.000000          2015.0     -3.194000   \n",
       "25%                      0.008191          2015.0     -0.024300   \n",
       "50%                      0.013270          2015.0      0.006000   \n",
       "75%                      0.021189          2015.0      0.038300   \n",
       "max                      1.000000          2015.0      4.737000   \n",
       "\n",
       "       N-LivingAreaError  \n",
       "count            63945.0  \n",
       "mean                 1.0  \n",
       "std                  0.0  \n",
       "min                  1.0  \n",
       "25%                  1.0  \n",
       "50%                  1.0  \n",
       "75%                  1.0  \n",
       "max                  1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[1].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have any real use for it, we can drop the `parcelid` feature. We will also drop , `Unnamed: 0` because it's a duplicate of `parcelid`.\n",
    "\n",
    "`assessmentyear` and `N-LivingAreaError` can be also dropped since the remaining values are for the most part the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_datasets:\n",
    "    i.drop(['parcelid','Unnamed: 0','assessmentyear', 'N-LivingAreaError'], axis=1, inplace=True)\n",
    "\n",
    "for i in test_datasets:\n",
    "    i.drop(['parcelid','Unnamed: 0','assessmentyear', 'N-LivingAreaError'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the scales of the values we have left. It looks like some features such as `calculatedfinishedsquarefeet` and `propertycountylandusecode` have much larger scales than the others. We will rescale all the features to the interval $[0,1]$, in order to have standardized values. We will use the same function that we used in the EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxRescaling(features, min_v=0, max_v=1):\n",
    "    scaler = MinMaxScaler(feature_range=(min_v, max_v), copy=False) #in place\n",
    "    scaler.fit(features)\n",
    "    return scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_datasets:\n",
    "    i[['calculatedfinishedsquarefeet','propertycountylandusecode']] = MinMaxRescaling(i[['calculatedfinishedsquarefeet','propertycountylandusecode']])\n",
    "\n",
    "for i in test_datasets:\n",
    "    i[['calculatedfinishedsquarefeet','propertycountylandusecode']] = MinMaxRescaling(i[['calculatedfinishedsquarefeet','propertycountylandusecode']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar8xvJ5kbrgl"
   },
   "source": [
    "## Predictions - Attempt 1 - k-NN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TdV2Wm4b8jx"
   },
   "source": [
    "### Why k-NN? - Introduction \n",
    "I chose the k-NN algorithm because, usually, the house construction doesn't happen randomly. It's really unusual that a private party builds his own house, with his own money, and wherever he likes: it's more likely that the municipality's dedicated office decides where and how the houses of a given zone are going to be buildt. \n",
    "\n",
    "Therefore, i think is safe to assume that houses of a given zone will have similar prices. The k-NN hopefully will help achiving this target. \n",
    "\n",
    "This attempt will use the [ScikitLearn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) of the k-NN algorithm for prediction.\n",
    "\n",
    "The first attempt will be conducted with the parameter `weights` set as \"uniform\", the second one will use the value \"distance\".\n",
    "\n",
    "The model will be tested with a number of neighbors beetween 2 and 20, because usually these are the value that yield the best results.\n",
    "\n",
    "The following snippet contains the functions that wrap the described procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7FkaJft9tOR2"
   },
   "outputs": [],
   "source": [
    "train, test = None, None\n",
    "n_neighbors = list(range(2,21))\n",
    "results = []\n",
    "types = ['distance', 'uniform']\n",
    "to_Y = ['logerror']\n",
    "to_X = list(set(train_datasets[1].columns) - set('logerror'))\n",
    "def train_test_kNN(x_train, y_train, x_test, y_test, n_neighbors, w='distance'):\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors, weights=w)\n",
    "    model = knn.fit(x_train, y_train)\n",
    "    prediction = model.predict(x_test)\n",
    "    scores = model.score(x_test, y_test)\n",
    "    diff = x_test.copy()\n",
    "    diff['diff'] = y_test - prediction\n",
    "    diff['diff'] = diff['diff'].abs()\n",
    "    data = {'n_neighbors': n_neighbors, \n",
    "            'weights': w,\n",
    "            'prediction': prediction,\n",
    "            'score' : scores,\n",
    "            'MSE': mean_squared_error(y_test,prediction),\n",
    "            'diff': diff\n",
    "           }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START - Dataset 1] at 2022-06-21 12:59:59.259655: n_neighbor = 2, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:00.395432 after 1.135777 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:00.395432: n_neighbor = 2, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:01.525166 after 1.129734 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:01.525166: n_neighbor = 3, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:02.749786 after 1.22462 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:02.749786: n_neighbor = 3, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:03.976027 after 1.226241 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:03.976027: n_neighbor = 4, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:05.369769 after 1.393742 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:05.369769: n_neighbor = 4, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:06.786952 after 1.417183 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:06.786952: n_neighbor = 5, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:08.136923 after 1.349971 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:08.136923: n_neighbor = 5, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:09.507276 after 1.370353 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:09.507276: n_neighbor = 6, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:10.949702 after 1.442426 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:10.951507: n_neighbor = 6, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:12.378186 after 1.426679 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:12.378186: n_neighbor = 7, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:13.825951 after 1.447765 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:13.825951: n_neighbor = 7, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:15.265962 after 1.440011 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:15.273359: n_neighbor = 8, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:16.801826 after 1.528467 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:16.801826: n_neighbor = 8, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:18.292824 after 1.490998 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:18.292824: n_neighbor = 9, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:19.827414 after 1.53459 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:19.827414: n_neighbor = 9, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:21.468692 after 1.641278 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:21.468692: n_neighbor = 10, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:23.175141 after 1.706449 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:23.175141: n_neighbor = 10, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:24.810964 after 1.635823 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:24.810964: n_neighbor = 11, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:26.585362 after 1.774398 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:26.585362: n_neighbor = 11, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:28.316417 after 1.731055 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:28.316417: n_neighbor = 12, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:30.098030 after 1.781613 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:30.098030: n_neighbor = 12, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:31.868082 after 1.770052 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:31.868082: n_neighbor = 13, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:33.679054 after 1.810972 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:33.679054: n_neighbor = 13, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:35.518643 after 1.839589 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:35.521816: n_neighbor = 14, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:37.560700 after 2.038884 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:37.560700: n_neighbor = 14, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:39.586851 after 2.026151 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:39.586851: n_neighbor = 15, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:41.529447 after 1.942596 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:41.530446: n_neighbor = 15, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:43.478645 after 1.948199 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:43.478645: n_neighbor = 16, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:45.362718 after 1.884073 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:45.362718: n_neighbor = 16, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:47.263137 after 1.900419 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:47.263137: n_neighbor = 17, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:49.187173 after 1.924036 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:49.187173: n_neighbor = 17, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:51.094889 after 1.907716 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:51.096696: n_neighbor = 18, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:53.076628 after 1.979932 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:53.078053: n_neighbor = 18, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:55.076880 after 1.998827 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:55.076880: n_neighbor = 19, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:57.052934 after 1.976054 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:57.052934: n_neighbor = 19, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:00:59.029189 after 1.976255 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:00:59.030949: n_neighbor = 20, weight = distance\n",
      "[END   - Dataset 1] at 2022-06-21 13:01:01.080931 after 2.049982 seconds. \n",
      "[START - Dataset 1] at 2022-06-21 13:01:01.080931: n_neighbor = 20, weight = uniform\n",
      "[END   - Dataset 1] at 2022-06-21 13:01:03.118180 after 2.037249 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:03.118180: n_neighbor = 2, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:03.939943 after 0.821763 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:03.939943: n_neighbor = 2, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:04.765677 after 0.825734 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:04.765677: n_neighbor = 3, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:05.666934 after 0.901257 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:05.666934: n_neighbor = 3, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:06.574586 after 0.907652 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:06.574586: n_neighbor = 4, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:07.561039 after 0.986453 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:07.561039: n_neighbor = 4, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:08.568848 after 1.007809 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:08.568848: n_neighbor = 5, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:09.790172 after 1.221324 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:09.790810: n_neighbor = 5, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:10.882923 after 1.092113 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:10.882923: n_neighbor = 6, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:12.031134 after 1.148211 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:12.031134: n_neighbor = 6, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:13.211817 after 1.180683 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:13.211817: n_neighbor = 7, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:14.416955 after 1.205138 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:14.417090: n_neighbor = 7, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:15.693941 after 1.276851 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:15.693941: n_neighbor = 8, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:16.943650 after 1.249709 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:16.943650: n_neighbor = 8, weight = uniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[END   - Dataset 2] at 2022-06-21 13:01:18.180905 after 1.237255 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:18.181672: n_neighbor = 9, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:19.444155 after 1.262483 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:19.444155: n_neighbor = 9, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:20.697712 after 1.253557 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:20.697712: n_neighbor = 10, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:22.004581 after 1.306869 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:22.004581: n_neighbor = 10, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:23.280091 after 1.27551 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:23.281697: n_neighbor = 11, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:24.631199 after 1.349502 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:24.631199: n_neighbor = 11, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:26.088651 after 1.457452 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:26.088917: n_neighbor = 12, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:27.487121 after 1.398204 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:27.487121: n_neighbor = 12, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:28.841594 after 1.354473 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:28.842326: n_neighbor = 13, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:30.268893 after 1.426567 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:30.268893: n_neighbor = 13, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:31.679724 after 1.410831 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:31.679724: n_neighbor = 14, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:33.127014 after 1.44729 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:33.127014: n_neighbor = 14, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:34.531321 after 1.404307 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:34.533011: n_neighbor = 15, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:35.989456 after 1.456445 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:35.989456: n_neighbor = 15, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:37.435061 after 1.445605 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:37.436636: n_neighbor = 16, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:38.914349 after 1.477713 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:38.914349: n_neighbor = 16, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:40.488279 after 1.57393 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:40.488279: n_neighbor = 17, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:42.379936 after 1.891657 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:42.379936: n_neighbor = 17, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:44.175934 after 1.795998 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:44.177660: n_neighbor = 18, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:45.834468 after 1.656808 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:45.834468: n_neighbor = 18, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:47.481998 after 1.64753 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:47.481998: n_neighbor = 19, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:49.168215 after 1.686217 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:49.168215: n_neighbor = 19, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:50.805879 after 1.637664 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:50.805879: n_neighbor = 20, weight = distance\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:52.519025 after 1.713146 seconds. \n",
      "[START - Dataset 2] at 2022-06-21 13:01:52.519296: n_neighbor = 20, weight = uniform\n",
      "[END   - Dataset 2] at 2022-06-21 13:01:54.287148 after 1.767852 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:01:54.287348: n_neighbor = 2, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:01:55.145961 after 0.858613 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:01:55.146949: n_neighbor = 2, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:01:55.982060 after 0.835111 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:01:55.982060: n_neighbor = 3, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:01:56.964324 after 0.982264 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:01:56.964324: n_neighbor = 3, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:01:57.993844 after 1.02952 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:01:57.994758: n_neighbor = 4, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:01:59.068976 after 1.074218 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:01:59.068976: n_neighbor = 4, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:00.032810 after 0.963834 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:00.032810: n_neighbor = 5, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:01.057342 after 1.024532 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:01.057518: n_neighbor = 5, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:02.106141 after 1.048623 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:02.106141: n_neighbor = 6, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:03.273515 after 1.167374 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:03.273515: n_neighbor = 6, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:04.385062 after 1.111547 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:04.385799: n_neighbor = 7, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:05.556110 after 1.170311 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:05.557110: n_neighbor = 7, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:06.725840 after 1.16873 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:06.726025: n_neighbor = 8, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:07.874180 after 1.148155 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:07.875179: n_neighbor = 8, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:09.055551 after 1.180372 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:09.056399: n_neighbor = 9, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:10.252205 after 1.195806 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:10.252646: n_neighbor = 9, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:11.467833 after 1.215187 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:11.468580: n_neighbor = 10, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:12.751093 after 1.282513 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:12.751532: n_neighbor = 10, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:14.260437 after 1.508905 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:14.260553: n_neighbor = 11, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:15.624363 after 1.36381 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:15.624363: n_neighbor = 11, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:17.010977 after 1.386614 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:17.010977: n_neighbor = 12, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:18.339886 after 1.328909 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:18.339886: n_neighbor = 12, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:19.693136 after 1.35325 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:19.693136: n_neighbor = 13, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:21.086849 after 1.393713 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:21.088358: n_neighbor = 13, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:22.472931 after 1.384573 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:22.473865: n_neighbor = 14, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:23.893678 after 1.419813 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:23.894214: n_neighbor = 14, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:25.298486 after 1.404272 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:25.298486: n_neighbor = 15, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:26.719013 after 1.420527 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:26.720010: n_neighbor = 15, weight = uniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[END   - Dataset 3] at 2022-06-21 13:02:28.227982 after 1.507972 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:28.227982: n_neighbor = 16, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:29.901671 after 1.673689 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:29.902190: n_neighbor = 16, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:31.417421 after 1.515231 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:31.417421: n_neighbor = 17, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:32.897783 after 1.480362 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:32.897783: n_neighbor = 17, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:34.351712 after 1.453929 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:34.351712: n_neighbor = 18, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:35.830648 after 1.478936 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:35.830648: n_neighbor = 18, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:37.350869 after 1.520221 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:37.350869: n_neighbor = 19, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:38.988835 after 1.637966 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:38.988835: n_neighbor = 19, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:40.580191 after 1.591356 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:40.580437: n_neighbor = 20, weight = distance\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:42.231085 after 1.650648 seconds. \n",
      "[START - Dataset 3] at 2022-06-21 13:02:42.231085: n_neighbor = 20, weight = uniform\n",
      "[END   - Dataset 3] at 2022-06-21 13:02:43.866729 after 1.635644 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:43.866729: n_neighbor = 2, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:44.763109 after 0.89638 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:44.763109: n_neighbor = 2, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:45.760296 after 0.997187 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:45.760296: n_neighbor = 3, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:46.833593 after 1.073297 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:46.833593: n_neighbor = 3, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:47.799256 after 0.965663 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:47.799256: n_neighbor = 4, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:48.852426 after 1.05317 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:48.852426: n_neighbor = 4, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:49.866768 after 1.014342 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:49.866768: n_neighbor = 5, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:50.980962 after 1.114194 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:50.980962: n_neighbor = 5, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:52.046397 after 1.065435 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:52.046397: n_neighbor = 6, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:53.214993 after 1.168596 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:53.214993: n_neighbor = 6, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:54.429271 after 1.214278 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:54.430056: n_neighbor = 7, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:55.727270 after 1.297214 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:55.727270: n_neighbor = 7, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:57.091100 after 1.36383 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:57.092096: n_neighbor = 8, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:58.364889 after 1.272793 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:58.364889: n_neighbor = 8, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:02:59.618714 after 1.253825 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:02:59.618714: n_neighbor = 9, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:01.047223 after 1.428509 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:01.047223: n_neighbor = 9, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:02.871709 after 1.824486 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:02.871709: n_neighbor = 10, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:04.503666 after 1.631957 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:04.503666: n_neighbor = 10, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:06.179719 after 1.676053 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:06.179719: n_neighbor = 11, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:07.881330 after 1.701611 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:07.881330: n_neighbor = 11, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:09.443910 after 1.56258 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:09.443910: n_neighbor = 12, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:11.062278 after 1.618368 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:11.062278: n_neighbor = 12, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:12.816008 after 1.75373 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:12.816008: n_neighbor = 13, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:14.410224 after 1.594216 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:14.410224: n_neighbor = 13, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:15.923513 after 1.513289 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:15.927324: n_neighbor = 14, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:17.660957 after 1.733633 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:17.660957: n_neighbor = 14, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:19.227418 after 1.566461 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:19.229037: n_neighbor = 15, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:20.797520 after 1.568483 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:20.797520: n_neighbor = 15, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:22.343046 after 1.545526 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:22.343046: n_neighbor = 16, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:23.989249 after 1.646203 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:23.989249: n_neighbor = 16, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:25.604251 after 1.615002 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:25.605768: n_neighbor = 17, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:27.228456 after 1.622688 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:27.228456: n_neighbor = 17, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:28.832608 after 1.604152 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:28.832608: n_neighbor = 18, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:30.498963 after 1.666355 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:30.499885: n_neighbor = 18, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:32.316491 after 1.816606 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:32.316491: n_neighbor = 19, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:34.586587 after 2.270096 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:34.586587: n_neighbor = 19, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:36.756544 after 2.169957 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:36.756544: n_neighbor = 20, weight = distance\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:38.770929 after 2.014385 seconds. \n",
      "[START - Dataset 4] at 2022-06-21 13:03:38.770929: n_neighbor = 20, weight = uniform\n",
      "[END   - Dataset 4] at 2022-06-21 13:03:40.692436 after 1.921507 seconds. \n",
      "CPU times: total: 3min 37s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(train_datasets)):\n",
    "    train = train_datasets[i]\n",
    "    test  = test_datasets[i]\n",
    "    for n in n_neighbors:\n",
    "        for w in types:\n",
    "            timestamp1 = datetime.now()\n",
    "            print(f\"[START - Dataset {i + 1}] at {timestamp1}: n_neighbor = {n}, weight = {w}\")\n",
    "            results.append(train_test_kNN(train[to_X], train[to_Y], test[to_X], test[to_Y], n, w))\n",
    "            timestamp2 = datetime.now()\n",
    "            difference = timestamp2 - timestamp1\n",
    "            print(f\"[END   - Dataset {i + 1}] at {timestamp2} after {difference.total_seconds()} seconds. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPlmoW8Bd0UP"
   },
   "source": [
    "### How did it go? - Evaluation\n",
    "After obtaining the results, we can proceed with the evaluation of the results.\n",
    "\n",
    "In order to keep this notebook as clean as possible, the evaluation will be done with the built-in evaluator of the KNeighborsRegressor object. The evaluation uses the $R^2$ index, the coefficient of determination that is $1 - \\frac{u}{v}$, where $u$ is the residual sum of squares and $v$ is the total sum of squares.\n",
    "\n",
    "We will also use the function \"mean_squared_error\" from Sklearn's module \"metrics\", to calculate the $MSE$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dkMbdppjvYVu"
   },
   "outputs": [],
   "source": [
    "def set_subplot(ax, title, x_label, y_label, color, par, score='score'):\n",
    "    if score == 'score':\n",
    "        ax.scatter(par['n_neighbors'], par['score'], color=color, label='data')\n",
    "    else:\n",
    "        ax.scatter(par['n_neighbors'], par['MSE'], color=color, label='data')\n",
    "    ax.get_yaxis().get_major_formatter().set_useOffset(False)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "\n",
    "def show_results_kNN(data):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "    for parameters in data:\n",
    "        if parameters['weights'] == \"uniform\":\n",
    "            set_subplot(ax1, 'Uniform', 'Number of neighbors', 'R^2 index', 'darkorange', parameters)\n",
    "            set_subplot(ax3, '', 'Number of neighbors', 'Mean Squared Error', 'darkorange', parameters)\n",
    "        else:\n",
    "            set_subplot(ax2, 'Distance', 'Number of neighbors', '', 'blue', parameters, score='MSE')\n",
    "            set_subplot(ax4, '', 'Number of neighbors', '', 'blue', parameters, score='MSE')  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results_kNN(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to remind that by default the \"distance\" used in those cases is the Minkowski distance. With other parameters, it may have yielded other results, but for the purpose of this project it is a reasonable choice.\n",
    "\n",
    "These results show that the parameter \"weights\" yields comparable scores for the two tested values. It looks like the $R^2 index$ gets better as the number of neighbors approaches 5, then it slowly decreases. It happens more or less the same for the $MSE$, but this metric decreases after the aforementioned value.\n",
    "\n",
    "The results are acceptable for the means of this project, and show that the algorithm probably did not overfit. It is advisable though that more tests are conducted with the 2017 dataset. The value of the $MSE$ metric suggests that the model's precision is acceptable. It looks like increasing the value of $k$ also increases the value of the $MSE$.\n",
    "\n",
    "We will now try to find some pattern from the instances that yielded the best results and the ones that yielded the worst ones. This comparison will be repeated for the two models with the best and the worst scores.\n",
    "\n",
    "In order to obtain the best and the worst models, they will be sorted in descending order by the $R^2$ index value and then in ascending order by the $MSE$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = results\n",
    "best.sort(key=lambda p: p['score'], reverse=True)\n",
    "best.sort(key=lambda p: p['MSE'])\n",
    "worst = best[len(best) - 1]\n",
    "best = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logerror</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>propertycountylandusecode</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.108762</td>\n",
       "      <td>0.051209</td>\n",
       "      <td>0.431272</td>\n",
       "      <td>1.541482e-02</td>\n",
       "      <td>0.456992</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.272959</td>\n",
       "      <td>0.102431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.540822</td>\n",
       "      <td>0.033674</td>\n",
       "      <td>0.217093</td>\n",
       "      <td>1.207413e-02</td>\n",
       "      <td>0.261802</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.290656</td>\n",
       "      <td>0.218259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.194000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>4.020909e-07</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.108950</td>\n",
       "      <td>0.032819</td>\n",
       "      <td>0.340154</td>\n",
       "      <td>6.989445e-03</td>\n",
       "      <td>0.424665</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.016900</td>\n",
       "      <td>0.065164</td>\n",
       "      <td>0.449701</td>\n",
       "      <td>1.556770e-02</td>\n",
       "      <td>0.566136</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.008030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.030275</td>\n",
       "      <td>0.070686</td>\n",
       "      <td>0.569596</td>\n",
       "      <td>2.229144e-02</td>\n",
       "      <td>0.600736</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.438776</td>\n",
       "      <td>0.055793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.544000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.695250</td>\n",
       "      <td>3.230448e-02</td>\n",
       "      <td>0.685765</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.627611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logerror  calculatedfinishedsquarefeet  latitude  \\\n",
       "count  8.000000                      8.000000  8.000000   \n",
       "mean  -0.108762                      0.051209  0.431272   \n",
       "std    1.540822                      0.033674  0.217093   \n",
       "min   -3.194000                      0.000000  0.000508   \n",
       "25%   -0.108950                      0.032819  0.340154   \n",
       "50%   -0.016900                      0.065164  0.449701   \n",
       "75%    0.030275                      0.070686  0.569596   \n",
       "max    2.544000                      0.090000  0.695250   \n",
       "\n",
       "       structuretaxvaluedollarcnt  longitude  lotsizesquarefeet  \\\n",
       "count                8.000000e+00   8.000000           8.000000   \n",
       "mean                 1.541482e-02   0.456992           0.001445   \n",
       "std                  1.207413e-02   0.261802           0.001616   \n",
       "min                  4.020909e-07   0.000270           0.000038   \n",
       "25%                  6.989445e-03   0.424665           0.000392   \n",
       "50%                  1.556770e-02   0.566136           0.001072   \n",
       "75%                  2.229144e-02   0.600736           0.001745   \n",
       "max                  3.230448e-02   0.685765           0.005007   \n",
       "\n",
       "       propertycountylandusecode      diff  \n",
       "count                   8.000000  8.000000  \n",
       "mean                    0.272959  0.102431  \n",
       "std                     0.290656  0.218259  \n",
       "min                     0.000000  0.000000  \n",
       "25%                     0.091837  0.000525  \n",
       "50%                     0.142857  0.008030  \n",
       "75%                     0.438776  0.055793  \n",
       "max                     0.755102  0.627611  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best['diff'].iloc[best['diff'].idxmin(), :].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logerror</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>propertycountylandusecode</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.108762</td>\n",
       "      <td>0.051209</td>\n",
       "      <td>0.431272</td>\n",
       "      <td>1.541482e-02</td>\n",
       "      <td>0.456992</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.272959</td>\n",
       "      <td>0.102431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.540822</td>\n",
       "      <td>0.033674</td>\n",
       "      <td>0.217093</td>\n",
       "      <td>1.207413e-02</td>\n",
       "      <td>0.261802</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.290656</td>\n",
       "      <td>0.218259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.194000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>4.020909e-07</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.108950</td>\n",
       "      <td>0.032819</td>\n",
       "      <td>0.340154</td>\n",
       "      <td>6.989445e-03</td>\n",
       "      <td>0.424665</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.016900</td>\n",
       "      <td>0.065164</td>\n",
       "      <td>0.449701</td>\n",
       "      <td>1.556770e-02</td>\n",
       "      <td>0.566136</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.008030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.030275</td>\n",
       "      <td>0.070686</td>\n",
       "      <td>0.569596</td>\n",
       "      <td>2.229144e-02</td>\n",
       "      <td>0.600736</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.438776</td>\n",
       "      <td>0.055793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.544000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.695250</td>\n",
       "      <td>3.230448e-02</td>\n",
       "      <td>0.685765</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.627611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logerror  calculatedfinishedsquarefeet  latitude  \\\n",
       "count  8.000000                      8.000000  8.000000   \n",
       "mean  -0.108762                      0.051209  0.431272   \n",
       "std    1.540822                      0.033674  0.217093   \n",
       "min   -3.194000                      0.000000  0.000508   \n",
       "25%   -0.108950                      0.032819  0.340154   \n",
       "50%   -0.016900                      0.065164  0.449701   \n",
       "75%    0.030275                      0.070686  0.569596   \n",
       "max    2.544000                      0.090000  0.695250   \n",
       "\n",
       "       structuretaxvaluedollarcnt  longitude  lotsizesquarefeet  \\\n",
       "count                8.000000e+00   8.000000           8.000000   \n",
       "mean                 1.541482e-02   0.456992           0.001445   \n",
       "std                  1.207413e-02   0.261802           0.001616   \n",
       "min                  4.020909e-07   0.000270           0.000038   \n",
       "25%                  6.989445e-03   0.424665           0.000392   \n",
       "50%                  1.556770e-02   0.566136           0.001072   \n",
       "75%                  2.229144e-02   0.600736           0.001745   \n",
       "max                  3.230448e-02   0.685765           0.005007   \n",
       "\n",
       "       propertycountylandusecode      diff  \n",
       "count                   8.000000  8.000000  \n",
       "mean                    0.272959  0.102431  \n",
       "std                     0.290656  0.218259  \n",
       "min                     0.000000  0.000000  \n",
       "25%                     0.091837  0.000525  \n",
       "50%                     0.142857  0.008030  \n",
       "75%                     0.438776  0.055793  \n",
       "max                     0.755102  0.627611  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best['diff'].iloc[best['diff'].idxmin(), :].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logerror</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>propertycountylandusecode</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.006362</td>\n",
       "      <td>0.085137</td>\n",
       "      <td>0.549478</td>\n",
       "      <td>0.012546</td>\n",
       "      <td>0.555761</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.006724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.041242</td>\n",
       "      <td>0.049930</td>\n",
       "      <td>0.127969</td>\n",
       "      <td>0.007145</td>\n",
       "      <td>0.223396</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.378741</td>\n",
       "      <td>0.009439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.086600</td>\n",
       "      <td>0.023406</td>\n",
       "      <td>0.370947</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.086196</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.016000</td>\n",
       "      <td>0.061210</td>\n",
       "      <td>0.462667</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>0.514919</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.075310</td>\n",
       "      <td>0.589575</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>0.564919</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.003122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.115105</td>\n",
       "      <td>0.622434</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>0.656849</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.005289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.173376</td>\n",
       "      <td>0.733355</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>0.812639</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.029010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logerror  calculatedfinishedsquarefeet  latitude  \\\n",
       "count  8.000000                      8.000000  8.000000   \n",
       "mean  -0.006362                      0.085137  0.549478   \n",
       "std    0.041242                      0.049930  0.127969   \n",
       "min   -0.086600                      0.023406  0.370947   \n",
       "25%   -0.016000                      0.061210  0.462667   \n",
       "50%    0.005000                      0.075310  0.589575   \n",
       "75%    0.014150                      0.115105  0.622434   \n",
       "max    0.041100                      0.173376  0.733355   \n",
       "\n",
       "       structuretaxvaluedollarcnt  longitude  lotsizesquarefeet  \\\n",
       "count                    8.000000   8.000000           8.000000   \n",
       "mean                     0.012546   0.555761           0.002219   \n",
       "std                      0.007145   0.223396           0.001830   \n",
       "min                      0.003308   0.086196           0.000691   \n",
       "25%                      0.008570   0.514919           0.001186   \n",
       "50%                      0.012126   0.564919           0.001498   \n",
       "75%                      0.016457   0.656849           0.002585   \n",
       "max                      0.025027   0.812639           0.006303   \n",
       "\n",
       "       propertycountylandusecode      diff  \n",
       "count                   8.000000  8.000000  \n",
       "mean                    0.303571  0.006724  \n",
       "std                     0.378741  0.009439  \n",
       "min                     0.000000  0.001300  \n",
       "25%                     0.000000  0.001916  \n",
       "50%                     0.081633  0.003122  \n",
       "75%                     0.704082  0.005289  \n",
       "max                     0.795918  0.029010  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst['diff'].iloc[best['diff'].idxmin(), :].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logerror</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>propertycountylandusecode</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.006362</td>\n",
       "      <td>0.085137</td>\n",
       "      <td>0.549478</td>\n",
       "      <td>0.012546</td>\n",
       "      <td>0.555761</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.006724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.041242</td>\n",
       "      <td>0.049930</td>\n",
       "      <td>0.127969</td>\n",
       "      <td>0.007145</td>\n",
       "      <td>0.223396</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.378741</td>\n",
       "      <td>0.009439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.086600</td>\n",
       "      <td>0.023406</td>\n",
       "      <td>0.370947</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.086196</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.016000</td>\n",
       "      <td>0.061210</td>\n",
       "      <td>0.462667</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>0.514919</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.075310</td>\n",
       "      <td>0.589575</td>\n",
       "      <td>0.012126</td>\n",
       "      <td>0.564919</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.003122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.115105</td>\n",
       "      <td>0.622434</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>0.656849</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.704082</td>\n",
       "      <td>0.005289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.173376</td>\n",
       "      <td>0.733355</td>\n",
       "      <td>0.025027</td>\n",
       "      <td>0.812639</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.029010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logerror  calculatedfinishedsquarefeet  latitude  \\\n",
       "count  8.000000                      8.000000  8.000000   \n",
       "mean  -0.006362                      0.085137  0.549478   \n",
       "std    0.041242                      0.049930  0.127969   \n",
       "min   -0.086600                      0.023406  0.370947   \n",
       "25%   -0.016000                      0.061210  0.462667   \n",
       "50%    0.005000                      0.075310  0.589575   \n",
       "75%    0.014150                      0.115105  0.622434   \n",
       "max    0.041100                      0.173376  0.733355   \n",
       "\n",
       "       structuretaxvaluedollarcnt  longitude  lotsizesquarefeet  \\\n",
       "count                    8.000000   8.000000           8.000000   \n",
       "mean                     0.012546   0.555761           0.002219   \n",
       "std                      0.007145   0.223396           0.001830   \n",
       "min                      0.003308   0.086196           0.000691   \n",
       "25%                      0.008570   0.514919           0.001186   \n",
       "50%                      0.012126   0.564919           0.001498   \n",
       "75%                      0.016457   0.656849           0.002585   \n",
       "max                      0.025027   0.812639           0.006303   \n",
       "\n",
       "       propertycountylandusecode      diff  \n",
       "count                   8.000000  8.000000  \n",
       "mean                    0.303571  0.006724  \n",
       "std                     0.378741  0.009439  \n",
       "min                     0.000000  0.001300  \n",
       "25%                     0.000000  0.001916  \n",
       "50%                     0.081633  0.003122  \n",
       "75%                     0.704082  0.005289  \n",
       "max                     0.795918  0.029010  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst['diff'].iloc[best['diff'].idxmin(), :].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major differences that emerges are the following:\n",
    "\n",
    "* The best predicted and the worst predicted instances for both the best model are very similar.\n",
    "* The same thing happens with the worst model.\n",
    "* The best predicted instances are located in different places than the worst ones.\n",
    "* The scale for the logerror is wider in the best predicted instances.\n",
    "* The `structuretaxvaluedollarcnt` feature has a much lower scale in the best prediction instances.\n",
    "* The best predicted instances have a larger scale even for the `diff` values.\n",
    "* The worst predicted instances have a larger scale for the `calculatedfinishedsquarefeet` feature values.\n",
    "\n",
    "The other differences that may emerge do not seem to be relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVUf7WUQcI33"
   },
   "source": [
    "## Predictions - Attempt 2 - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jkCHkx0Hdsj"
   },
   "source": [
    "### Why Linear Regression? - Introduction\n",
    "The idea behind the adoption of the LinReg model is correlated to the low integrity of the inititial dataset. \n",
    "\n",
    "In contrast with the previously analyzed model, this is an attempt to see what would happen with an \"assumption-free\" model. It is expected that this type of analysis will underline some unseen correlations, and also will produce some interesting predictions.\n",
    "\n",
    "This test will be conducted with the [ScikitLearn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) of the LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3N2szLiTv7Oi"
   },
   "outputs": [],
   "source": [
    "def train_test_LinReg(x_train, y_train, x_test, y_test):\n",
    "    model = LinearRegression().fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    diff = x_test.copy()\n",
    "    diff['diff'] = y_test - predictions\n",
    "    diff['diff'] = diff['diff'].abs()\n",
    "    data = {\n",
    "        'predictions': predictions,\n",
    "        'R_sq': model.score(x_test, predictions),\n",
    "        'MSE': mean_squared_error(y_test, predictions),\n",
    "        'Adj_R_sq': 1 - (1-model.score(x_test, predictions))*(len(predictions)-1)/(len(predictions)-x_test.shape[1]-1),\n",
    "        'diff': diff\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 375 ms\n",
      "Wall time: 145 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = []\n",
    "to_Y = ['logerror']\n",
    "to_X = list(set(train.columns) - set('logerror'))\n",
    "for i in range(len(train_datasets)):\n",
    "    train = train_datasets[i]\n",
    "    test = test_datasets[i]\n",
    "    res.append(train_test_LinReg(train[to_X], train[to_Y], test[to_X], test[to_Y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHbgkxaTJqKL"
   },
   "source": [
    "### How did it go? - Evaluation\n",
    "We can now proceed with the evaluation of the results.\n",
    "\n",
    "The following tests will be used:\n",
    "\n",
    "*  Mean Squared Error\n",
    "*  R-squared index\n",
    "*  Adjusted R-squared index\n",
    "\n",
    "The evaluations will be done by using the [ScikitLearn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results_LinReg(results):\n",
    "    for i in range(len(results)):\n",
    "        parameters = results[i]\n",
    "        print(f\"[Experiment number {i  + 1}]\\n[Scores] R_sq index = {parameters['R_sq']}, \" + \n",
    "              f\"MSE = {parameters['MSE']}, Adj_R_sq index = {parameters['Adj_R_sq']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Experiment number 1]\n",
      "[Scores] R_sq index = 1.0, MSE = 5.180732657079307e-32, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 2]\n",
      "[Scores] R_sq index = 1.0, MSE = 1.5997705511909795e-31, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 3]\n",
      "[Scores] R_sq index = 1.0, MSE = 4.220604731225047e-32, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 4]\n",
      "[Scores] R_sq index = 1.0, MSE = 4.419750797908636e-32, Adj_R_sq index = 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_results_LinReg(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the results it is clear that the results are too good to be true. It is clear that this is a case of overfitting. [This article](https://statisticsbyjim.com/regression/r-squared-too-high/) explains the other possible reasons of these results. The final section of the document investigates the causes of this failure.\n",
    "\n",
    "It may have been interesting analysing the best and the worst prediction instances for the test conducted in this section, but it's clear that that would be pointless, due to the overall failure of the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVUf7WUQcI33"
   },
   "source": [
    "## Predictions - Attempt 3 - Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jkCHkx0Hdsj"
   },
   "source": [
    "### Why Support Vector Regression? - Introduction\n",
    "\n",
    "After the failure of the Linear Regression Model, this one should yield better results.\n",
    "\n",
    "This test will be conducted with the [ScikitLearn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR) of the Support Vector Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3N2szLiTv7Oi"
   },
   "outputs": [],
   "source": [
    "def train_test_SVR(x_train, y_train, x_test, y_test, C_val, Ep_val):\n",
    "    model = SVR(C=C_val, epsilon=Ep_val).fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    data = {\n",
    "        'C': C_val,\n",
    "        'epsilon': Ep_val,\n",
    "        'predictions': predictions,\n",
    "        'R_sq': model.score(x_test, predictions),\n",
    "        'MSE': mean_squared_error(y_test, predictions),\n",
    "        'Adj_R_sq': 1 - (1-model.score(x_test, predictions))*(len(predictions)-1)/(len(predictions)-x_test.shape[1]-1),\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will be tested with the `C` parameter values ranging in $[0.8,1.2]$, and the values of the `epsilon` parameter ranging in $[0.1,0.3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\nsimo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 55.7 s\n",
      "Wall time: 57.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_svr = []\n",
    "to_Y = ['logerror']\n",
    "to_X = list(set(train.columns) - set('logerror'))\n",
    "C_values = [0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3]\n",
    "Ep_values = [0.1,0.2,0.3]\n",
    "for i in range(len(train_datasets)):\n",
    "    train = train_datasets[i]\n",
    "    test = test_datasets[i]\n",
    "    for c in C_values:\n",
    "        for ep in Ep_values:\n",
    "            res_svr.append(train_test_SVR(train[to_X], train[to_Y], test[to_X], test[to_Y], c, ep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHbgkxaTJqKL"
   },
   "source": [
    "### How did it go? - Evaluation\n",
    "We can now proceed with the evaluation of the results.\n",
    "\n",
    "The following tests will be used:\n",
    "\n",
    "*  Mean Squared Error\n",
    "*  R-squared index\n",
    "*  Adjusted R-squared index\n",
    "\n",
    "The evaluations will be done by using the [ScikitLearn Metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results_SVR(results):\n",
    "    for i in range(len(results)):\n",
    "        parameters = results[i]\n",
    "        print(f\"[Experiment number {i  + 1}] \\n\" +\n",
    "              f\"[Parameters] C: {parameters['C']}, epsilon: {parameters['epsilon']}\"\n",
    "              f\"\\n[Scores] R_sq index = {parameters['R_sq']}, \" + \n",
    "              f\"MSE = {parameters['MSE']}, Adj_R_sq index = {parameters['Adj_R_sq']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Experiment number 1] \n",
      "[Parameters] C: 0.6, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.00242448755474935, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 2] \n",
      "[Parameters] C: 0.6, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.00269487446345679, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 3] \n",
      "[Parameters] C: 0.6, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.00601519197667765, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 4] \n",
      "[Parameters] C: 0.7, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002195154506737165, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 5] \n",
      "[Parameters] C: 0.7, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0030302801623625654, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 6] \n",
      "[Parameters] C: 0.7, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005280923123244953, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 7] \n",
      "[Parameters] C: 0.8, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021892767249635883, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 8] \n",
      "[Parameters] C: 0.8, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0030868911420188633, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 9] \n",
      "[Parameters] C: 0.8, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.00524335446399238, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 10] \n",
      "[Parameters] C: 0.9, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021773207417077607, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 11] \n",
      "[Parameters] C: 0.9, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.003122500091672513, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 12] \n",
      "[Parameters] C: 0.9, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005062354017790979, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 13] \n",
      "[Parameters] C: 1.0, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021357055925233393, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 14] \n",
      "[Parameters] C: 1.0, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.003098672427402108, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 15] \n",
      "[Parameters] C: 1.0, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.004904240120367078, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 16] \n",
      "[Parameters] C: 1.1, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002079731903167693, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 17] \n",
      "[Parameters] C: 1.1, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.003088521694162264, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 18] \n",
      "[Parameters] C: 1.1, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0047915975746930335, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 19] \n",
      "[Parameters] C: 1.2, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021201046714906585, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 20] \n",
      "[Parameters] C: 1.2, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0029596566453689186, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 21] \n",
      "[Parameters] C: 1.2, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0040180133321618535, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 22] \n",
      "[Parameters] C: 1.3, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0020922441936872347, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 23] \n",
      "[Parameters] C: 1.3, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002687085689636234, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 24] \n",
      "[Parameters] C: 1.3, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0031311773168437103, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 25] \n",
      "[Parameters] C: 0.6, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006466319249013676, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 26] \n",
      "[Parameters] C: 0.6, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0072620301427153144, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 27] \n",
      "[Parameters] C: 0.6, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.012296698302543678, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 28] \n",
      "[Parameters] C: 0.7, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006581180923061181, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 29] \n",
      "[Parameters] C: 0.7, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0073418334586010155, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 30] \n",
      "[Parameters] C: 0.7, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.013934649369517351, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 31] \n",
      "[Parameters] C: 0.8, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0062163476647920015, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 32] \n",
      "[Parameters] C: 0.8, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0074231210108103894, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 33] \n",
      "[Parameters] C: 0.8, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.01624164993928612, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 34] \n",
      "[Parameters] C: 0.9, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006000486306746524, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 35] \n",
      "[Parameters] C: 0.9, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007415172257029819, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 36] \n",
      "[Parameters] C: 0.9, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.01799142667670353, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 37] \n",
      "[Parameters] C: 1.0, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005793786220610262, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 38] \n",
      "[Parameters] C: 1.0, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0073717407248949235, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 39] \n",
      "[Parameters] C: 1.0, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.018275513746518503, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 40] \n",
      "[Parameters] C: 1.1, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005702891322064932, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 41] \n",
      "[Parameters] C: 1.1, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007293108398685399, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 42] \n",
      "[Parameters] C: 1.1, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.018426223574151464, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 43] \n",
      "[Parameters] C: 1.2, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005583902717160456, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 44] \n",
      "[Parameters] C: 1.2, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007161914628782096, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 45] \n",
      "[Parameters] C: 1.2, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.018586338337182397, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 46] \n",
      "[Parameters] C: 1.3, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005539415585091957, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 47] \n",
      "[Parameters] C: 1.3, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007106174364234134, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 48] \n",
      "[Parameters] C: 1.3, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.018724344114688648, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 49] \n",
      "[Parameters] C: 0.6, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021960273237753257, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 50] \n",
      "[Parameters] C: 0.6, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021953592362557927, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 51] \n",
      "[Parameters] C: 0.6, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0035910476161968106, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 52] \n",
      "[Parameters] C: 0.7, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002262703505870788, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 53] \n",
      "[Parameters] C: 0.7, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021851638363047723, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 54] \n",
      "[Parameters] C: 0.7, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0037218090364184203, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 55] \n",
      "[Parameters] C: 0.8, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0022169944790057295, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 56] \n",
      "[Parameters] C: 0.8, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0021775749516119458, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 57] \n",
      "[Parameters] C: 0.8, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.003710247617259962, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 58] \n",
      "[Parameters] C: 0.9, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0022271924163899796, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 59] \n",
      "[Parameters] C: 0.9, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0020971473621103124, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 60] \n",
      "[Parameters] C: 0.9, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0034638233016777067, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 61] \n",
      "[Parameters] C: 1.0, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0022729839966876744, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 62] \n",
      "[Parameters] C: 1.0, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0019585480889859775, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 63] \n",
      "[Parameters] C: 1.0, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.003114952770073622, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 64] \n",
      "[Parameters] C: 1.1, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0022939275504217627, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 65] \n",
      "[Parameters] C: 1.1, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0017957371239509408, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 66] \n",
      "[Parameters] C: 1.1, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0028164928816861133, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 67] \n",
      "[Parameters] C: 1.2, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002159924739585374, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 68] \n",
      "[Parameters] C: 1.2, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0016222776562294183, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 69] \n",
      "[Parameters] C: 1.2, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0026302909053977004, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 70] \n",
      "[Parameters] C: 1.3, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002110023930868907, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 71] \n",
      "[Parameters] C: 1.3, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0014967617355426783, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 72] \n",
      "[Parameters] C: 1.3, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.002543873080063591, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 73] \n",
      "[Parameters] C: 0.6, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0011002873705970508, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 74] \n",
      "[Parameters] C: 0.6, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.005312480378074033, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 75] \n",
      "[Parameters] C: 0.6, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.01119467115114165, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 76] \n",
      "[Parameters] C: 0.7, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0010774782656346937, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 77] \n",
      "[Parameters] C: 0.7, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006640434053002628, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 78] \n",
      "[Parameters] C: 0.7, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.01226049883104312, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 79] \n",
      "[Parameters] C: 0.8, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0010247669046061177, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 80] \n",
      "[Parameters] C: 0.8, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006860322174502624, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 81] \n",
      "[Parameters] C: 0.8, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.012557427784073023, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 82] \n",
      "[Parameters] C: 0.9, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0010292433205024497, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 83] \n",
      "[Parameters] C: 0.9, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006920362014964079, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 84] \n",
      "[Parameters] C: 0.9, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.013805552420664622, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 85] \n",
      "[Parameters] C: 1.0, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.001028882317501242, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 86] \n",
      "[Parameters] C: 1.0, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007189304007506841, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 87] \n",
      "[Parameters] C: 1.0, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.01474952079914836, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 88] \n",
      "[Parameters] C: 1.1, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0010193929272904463, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 89] \n",
      "[Parameters] C: 1.1, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.007228264764382355, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 90] \n",
      "[Parameters] C: 1.1, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.014883621652723646, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 91] \n",
      "[Parameters] C: 1.2, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0010228869023331294, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 92] \n",
      "[Parameters] C: 1.2, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006945545018154411, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 93] \n",
      "[Parameters] C: 1.2, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.012502280268190861, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 94] \n",
      "[Parameters] C: 1.3, epsilon: 0.1\n",
      "[Scores] R_sq index = 1.0, MSE = 0.0009757394833515869, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 95] \n",
      "[Parameters] C: 1.3, epsilon: 0.2\n",
      "[Scores] R_sq index = 1.0, MSE = 0.006086818111351068, Adj_R_sq index = 1.0\n",
      "\n",
      "\n",
      "[Experiment number 96] \n",
      "[Parameters] C: 1.3, epsilon: 0.3\n",
      "[Scores] R_sq index = 1.0, MSE = 0.010006032199306864, Adj_R_sq index = 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_results_SVR(res_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not as good as expected. The $R^2$ index is still very high, but this time the $MSE$ is reasonably low.\n",
    "\n",
    "This might be another case of overfitting. The causes of this may be the same as the ones found for the Linear Regression.\n",
    "\n",
    "Analysing the best and the worst prediction instances for the test conducted in this section would be pointless, for the same reasons as the previous algorithm tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN\n",
    "It is clear that the first regression algorithm is a more reasonable choice then the others. \n",
    "\n",
    "The k-NN algorithm did get the expected results. All the evaluation measures turned out to be very high. This is usually a good thing, but not necessarly in this case. The $R^2$ index near to 99% is good, and the $MSE$ values indicates that the model's precision is very close to be optimal.\n",
    "\n",
    "### LinReg & SVR\n",
    "The LinReg and the SVR models suffer from a suspect case of over-fitting, so the results are probably biased.\n",
    "\n",
    "The causes of these algorithms' failures may be found among the following:\n",
    "\n",
    "- `Data-related issues`: it is possible that, in the Explorative Data Analysis, the filling of the missing data may have lead to some kind of poisoning. The low number of training instances may be another possible cause.\n",
    "- `Wrong algorithm/approach`: the first and most probable cause, is the inner workings of the Linear Regression: it may just be the wrong model to obtain any useful information from.\n",
    "- `Biased evaluation indexes`: the second possibile cause is a bias contained in the testing measures. The analysis of other indexes may yield some more interesting results, but for now is impossible to declare the precise reason for the over-fitting to happen.\n",
    "\n",
    "It is advisable to use a different algorithm and a more complete dataset to retrieve better results.\n",
    "\n",
    "In order to confirm the overfitting, a test should be conducted with the data from the 2017 dataset."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Prediction - Simonato.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
